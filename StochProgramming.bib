Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Marla2020,
author = {Marla, Lavanya and Rikun, Alexander and Stauffer, Gautier and Pratsini, Eleni},
doi = {10.1016/j.orp.2020.100150},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Marla et al/Operations Research Perspectives/Marla et al. - 2020 - Often, the RO Approach and the CCPRobust Modeling and Planning Insights from Three Industrial Applications.pdf:pdf},
issn = {22147160},
journal = {Operations Research Perspectives},
month = {mar},
pages = {100150},
title = {{Often, the RO Approach and the CCPRobust Modeling and Planning: Insights from Three Industrial Applications}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2214716020300403},
year = {2020}
}
@article{Landsberg2003a,
abstract = {Forest models should in future combine the predictive power and flexibility of process-based models with the empirical information and descriptive accuracy of conventional mensuration-based models. Progress is likely to be rapid if model developers identify the potential users of their models and the needs of those users. Users include operational forest managers, planners, bureaucrats, politicians, community and environmental groups, scientists, and academics. Extant models that could be used immediately or could be adapted for use by these groups are reviewed. Currently available process-based models can provide good estimates of growth and biomass productivity at various scales; combined with conventional models they can provide information of the type required by managers and planners. Climate-driven models can provide good estimates of potential plantation productivity, while detailed process models contribute to our understanding of the way systems function and are essential for future progress. Technical challenges for the future include continued research on carbon-allocation processes, nutrient availability in soils, and nutrient uptake by trees. It is important that we have models that can be used to predict and analyze the effects of technologies such as clonal forestry and possible genetic manipulation, as well as intensive management in relation to nutrition, weed control, and disease control. Large-scale analysis of forest productivity is already possible using models driven by remote sensing; inclusion of nutrition should be a goal in this area. Moves towards active collaboration and the implementation of mixed models in operational systems, as well as improving communication between model developers and users, should ensure that practical problems are identified and fed back to modellers, which should lead to rapid progress.},
author = {Landsberg, Joe},
doi = {10.1139/x02-129},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Landsberg/Canadian Journal of Forest Research/Landsberg - 2003 - Modelling forest ecosystems State of the art, challenges, and future directions.PDF:PDF},
issn = {00455067},
journal = {Canadian Journal of Forest Research},
number = {3},
pages = {385--397},
title = {{Modelling forest ecosystems: State of the art, challenges, and future directions}},
volume = {33},
year = {2003}
}
@article{Dembo1990,
author = {Dembo, Ron S and Chiarri, Angel and Martin, Jesus Gomez and Paradinas, Luis},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Dembo et al. - 1990 - Managing Hidroel{\'{e}}ctrica Espa{\~{n}}ola's Hydroelectric Power System.pdf:pdf},
journal = {Interfaces},
number = {1},
pages = {115--135},
title = {{Managing Hidroel{\'{e}}ctrica Espa{\~{n}}ola's Hydroelectric Power System}},
url = {https://www.jstor.org/stable/25061315},
volume = {20},
year = {1990}
}
@article{Heitsch2009,
abstract = {An important issue for solving multistage stochastic programs consists$\backslash$nin the approximate representation of the (multivariate) stochastic$\backslash$ninput process in the form of a scenario tree. In this paper, we develop$\backslash$n(stability) theory-based heuristics for generating scenario trees$\backslash$nout of an initial set of scenarios. They are based on forward or$\backslash$nbackward algorithms for tree generation consisting of recursive scenario$\backslash$nreduction and bundling steps. Conditions are established implying$\backslash$ncloseness of optimal values of the original process and its tree$\backslash$napproximation, respectively, by relying on a recent stability result$\backslash$nin Heitsch, R{\{}{\"{o}}{\}}misch and Strugarek (SIAM J Optim 17:511--525,$\backslash$n2006) for multistage stochastic programs. Numerical experience is$\backslash$nreported for constructing multivariate scenario trees in electricity$\backslash$nportfolio management.},
author = {Heitsch, Holger and R{\"{o}}misch, Werner},
doi = {10.1007/s10107-007-0197-2},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Heitsch, R{\"{o}}misch - 2009 - Scenario tree modeling for multistage stochastic programs.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {Filtration,L r -distance,Multistage,Scenario reduction,Scenario tree,Stability,Stochastic programming},
month = {may},
number = {2},
pages = {371--406},
title = {{Scenario tree modeling for multistage stochastic programs}},
url = {http://link.springer.com/10.1007/s10107-007-0197-2},
volume = {118},
year = {2009}
}
@article{Chunlin2012,
abstract = {In this paper, an optimal model for the transportation of emergency resource is established on chance constrained stochastic programming. We use Conditional Value at Risk (CVaR) to approximate the chance constraint, and we get the approximation problem of the chance constrained stochastic programming by using the sample average approximation (SAA) method. For a given sample, the SAA problem is a deterministic nonlinear programming (NLP) and any appropriate NLP code can be applied to solve the problem. The model and method provide a new way for the emergency logistics management engineering.},
author = {Chunlin, Deng and Liu, Yang},
doi = {10.1016/j.sepro.2012.04.022},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Chunlin, Liu - 2012 - Sample Average Approximation Method for Chance Constrained Stochastic Programming in Transportation Model of Emerg.pdf:pdf},
issn = {22113819},
journal = {Systems Engineering Procedia},
keywords = {Conditional Value-at-Risk,chance constraint,conditional value-at-risk,emergency managemen engineering,sample average approximation,transportation,transportation model},
pages = {137--143},
title = {{Sample Average Approximation Method for Chance Constrained Stochastic Programming in Transportation Model of Emergency Management}},
url = {http://dx.doi.org/10.1016/j.sepro.2012.04.022},
volume = {5},
year = {2012}
}
@article{Veliz2014,
abstract = {We consider the important problem of medium term forest planning with an integrated approach considering both harvesting and road construction decisions in the presence of uncertainty modeled as a multi-stage problem. We give strengthening methods that enable the solution of problems with many more scenarios than previously reported in the literature. Furthermore, we demonstrate that a scenario-based decomposition method (Progressive Hedging) is competitive with direct solution of the extensive form, even on a serial computer. Computational results based on a real-world example are presented.},
author = {Veliz, Fernando Badilla and Watson, Jean-Paul and Weintraub, Andres and Wets, Roger J.-B. and Woodruff, David L.},
doi = {10.1007/s10479-014-1608-4},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Veliz et al. - 2014 - Stochastic optimization models in forest planning a progressive hedging solution approach.pdf:pdf},
isbn = {0254-5330},
issn = {0254-5330},
journal = {Annals of Operations Research},
keywords = {Forest harvest planning,Forestry,Progressive hedging,Stochastic programming,forest harvest planning,forestry,progressive hedging,stochastic},
month = {may},
pages = {259--274},
publisher = {Springer US},
title = {{Stochastic optimization models in forest planning: a progressive hedging solution approach}},
url = {http://link.springer.com/10.1007/s10479-014-1608-4},
year = {2014}
}
@article{Palluotto2019,
author = {Palluotto, Lorella and Dumont, Nicolas and Rodrigues, Pedro and Gicquel, Olivier and Vicquelin, Ronan},
doi = {10.1016/j.jqsrt.2019.07.013},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Palluotto et al. - 2019 - Assessment of randomized Quasi-Monte Carlo method efficiency in radiative heat transfer simulations.pdf:pdf},
issn = {00224073},
journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},
keywords = {Monte Carlo,Quasi-Monte Carlo,Low-discrepancy sequ},
pages = {106570},
publisher = {Elsevier Ltd},
title = {{Assessment of randomized Quasi-Monte Carlo method efficiency in radiative heat transfer simulations}},
url = {https://doi.org/10.1016/j.jqsrt.2019.07.013},
volume = {236},
year = {2019}
}
@article{Hooshmand2016a,
author = {Hooshmand, F and MirHassani, S.A.},
doi = {10.1080/10556788.2015.1088850},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hooshmand, MirHassani - 2016 - Efficient constraint reduction in multistage stochastic programming problems with endogenous uncertainty.pdf:pdf},
issn = {1055-6788},
journal = {Optimization Methods and Software},
month = {mar},
number = {2},
pages = {359--376},
title = {{Efficient constraint reduction in multistage stochastic programming problems with endogenous uncertainty}},
url = {http://www.tandfonline.com/doi/full/10.1080/10556788.2015.1088850},
volume = {31},
year = {2016}
}
@article{Growe-Kuska2003,
abstract = { Portfolio and risk management problems of power utilities may be modeled by multistage stochastic programs. These models use a set of scenarios and corresponding probabilities to model the multivariate random data process (electrical load, stream flows to hydro units, and fuel and electricity prices). For most practical problems the optimization problem that contains all possible scenarios is too large. Due to computational complexity and to time limitations this program is often approximated by a model involving a (much) smaller number of scenarios. The proposed reduction algorithms determine a subset of the initial scenario set and assign new probabilities to the preserved scenarios. The scenario tree construction algorithms successively reduce the number of nodes of a fan of individual scenarios by modifying the tree structure and by bundling similar scenarios. Numerical experience is reported for constructing scenario trees for the load and spot market prices entering a stochastic portfolio management model of a German utility.},
author = {Gr{\"{o}}we-Kuska, Nicole and Heitsch, Holger and R{\"{o}}misch, Werner},
doi = {10.1109/PTC.2003.1304379},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Gr{\"{o}}we-Kuska, Heitsch, R{\"{o}}misch - 2003 - Scenario reduction and scenario tree construction for power management problems.pdf:pdf},
isbn = {0780379675},
journal = {2003 IEEE Bologna PowerTech - Conference Proceedings},
keywords = {Scenario reduction,Scenario tree construction,Stochastic programming},
pages = {152--158},
title = {{Scenario reduction and scenario tree construction for power management problems}},
volume = {3},
year = {2003}
}
@article{Heitsch2011,
abstract = {An important issue for solving multistage stochastic programs consists$\backslash$nin the approximate representation of the (multivariate) stochastic$\backslash$ninput process in the form of a scenario tree. In this paper, we develop$\backslash$n(stability) theory-based heuristics for generating scenario trees$\backslash$nout of an initial set of scenarios. They are based on forward or$\backslash$nbackward algorithms for tree generation consisting of recursive scenario$\backslash$nreduction and bundling steps. Conditions are established implying$\backslash$ncloseness of optimal values of the original process and its tree$\backslash$napproximation, respectively, by relying on a recent stability result$\backslash$nin Heitsch, R{\{}{\"{o}}{\}}misch and Strugarek (SIAM J Optim 17:511--525,$\backslash$n2006) for multistage stochastic programs. Numerical experience is$\backslash$nreported for constructing multivariate scenario trees in electricity$\backslash$nportfolio management.},
author = {Heitsch, Holger and R{\"{o}}misch, Werner},
doi = {10.1007/s10287-008-0087-y},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Heitsch, R{\"{o}}misch - 2009 - Scenario tree reduction for multistage stochastic programs.pdf:pdf},
isbn = {0025-5610$\backslash$r1436-4646},
issn = {1619-697X},
journal = {Computational Management Science},
keywords = {Electricity,Multi-stage,Power portfolio,Scenario generation,Scenario reduction,Scenario tree,Stability,Stochastic programming},
month = {may},
number = {2},
pages = {117--133},
pmid = {26559747},
title = {{Scenario tree reduction for multistage stochastic programs}},
url = {http://link.springer.com/10.1007/s10287-008-0087-y},
volume = {6},
year = {2009}
}
@article{Thenie2008,
abstract = {Stochastic programming with step decision rules (SPSDR) aims to produce efficient solutions to multistage stochastic optimization problems. SPSDR, like plain multistage Stochastic Programming (SP), operates on a Monte Carlo "computing sample" of moderate size that approximates the stochastic process. Unlike SP, SPSDR does not strive to build a balanced event tree out of that sample. Rather, it defines a solution as a special type of decision rule, with the property that the decisions at each stage are piecewise constant functions on the sample of scenarios. Those pieces define a partition of the set of scenarios at each stage t, but the partition at t + 1 need not be refinement of the partition at t. However, the rule is constructed so that the non-anticipativity condition is met, a necessary condition to make the rules operational. To validate the method we show how to extend a non-anticipatory decision rule to arbitrary scenarios within a very large validation sample of scenarios. We apply three methods, SPSDR, SP and Robust Optimization, to the same 12-stage problem in supply chain management, and compare them relatively to different objectives and performance criteria. It appears that SPSDR performs better than SP in that it produces a more accurate estimate (prediction) of the value achieved by its solution on the validation sample, and also that the achieved value is better. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Th{\'{e}}ni{\'{e}}, J. and Vial, J. Ph},
doi = {10.1016/j.automatica.2008.02.001},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Th{\'{e}}ni{\'{e}}, Vial - 2008 - Step decision rules for multistage stochastic programming A heuristic approach.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Multistage stochastic programming},
number = {6},
pages = {1569--1584},
title = {{Step decision rules for multistage stochastic programming: A heuristic approach}},
volume = {44},
year = {2008}
}
@article{VanVuuren2011,
abstract = {This paper summarizes the development process and main characteristics of the Representative Concentration Pathways (RCPs), a set of four new pathways developed for the climate modeling community as a basis for long-term and near-term modeling experiments. The four RCPs together span the range of year 2100 radiative forcing values found in the open literature, i. e. from 2.6 to 8.5 W/m2. The RCPs are the product of an innovative collaboration between integrated assessment modelers, climate modelers, terrestrial ecosystem modelers and emission inventory experts. The resulting product forms a comprehensive data set with high spatial and sectoral resolutions for the period extending to 2100. Land use and emissions of air pollutants and greenhouse gases are reported mostly at a 0.5 × 0.5 degree spatial resolution, with air pollutants also provided per sector (for well-mixed gases, a coarser resolution is used). The underlying integrated assessment model outputs for land use, atmospheric emissions and concentration data were harmonized across models and scenarios to ensure consistency with historical observations while preserving individual scenario trends. For most variables, the RCPs cover a wide range of the existing literature. The RCPs are supplemented with extensions (Extended Concentration Pathways, ECPs), which allow climate modeling experiments through the year 2300. The RCPs are an important development in climate research and provide a potential foundation for further research and assessment, including emissions mitigation and impact analysis. {\textcopyright} 2011 The Author(s).},
author = {van Vuuren, Detlef P. and Edmonds, Jae and Kainuma, Mikiko and Riahi, Keywan and Thomson, Allison and Hibbard, Kathy and Hurtt, George C. and Kram, Tom and Krey, Volker and Lamarque, Jean Francois and Masui, Toshihiko and Meinshausen, Malte and Nakicenovic, Nebojsa and Smith, Steven J. and Rose, Steven K.},
doi = {10.1007/s10584-011-0148-z},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/van Vuuren et al. - 2011 - The representative concentration pathways An overview.pdf:pdf},
issn = {01650009},
journal = {Climatic Change},
number = {1},
pages = {5--31},
title = {{The representative concentration pathways: An overview}},
volume = {109},
year = {2011}
}
@article{Pour2017,
abstract = {We introduce a practical generalization of the standard personnel assignment problem. In this problem, we have a set of personnel and a set of lost and found centers. Each center receives a stochastic demand. Some constraints, namely, the work skills of different personnel, balancing workload while assigning personnel to the centers and some other practical constraints are taken into account. The objective function is to minimize the assignment cost and the cost occurred by the shortage of personnel in different centers due to the stochastic arrival of the demand over a given time period. We have developed a sample average approximation technique to solve the introduced problem. Computational tests for the studied problem show the effectiveness of the proposed method.},
author = {Pour, Amir Ghorbani and Naji-Azimi, Zahra and Salari, Majid},
doi = {10.1016/j.cie.2017.09.006},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pour, Naji-Azimi, Salari - 2017 - Sample average approximation method for a new stochastic personnel assignment problem.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Monte Carlo,Personnel assignment problem,Sample average approximation,Stochastic optimization},
pages = {135--143},
publisher = {Elsevier Ltd},
title = {{Sample average approximation method for a new stochastic personnel assignment problem}},
url = {https://doi.org/10.1016/j.cie.2017.09.006},
volume = {113},
year = {2017}
}
@article{Apap2017,
abstract = {In this work, we address the modeling and solution of mixed-integer linear multistage stochastic programming problems involving both endogenous and exogenous uncertain parameters. We first propose a composite scenario tree that captures both types of uncertainty, and we exploit its unique structure to derive new theoretical properties that can drastically reduce the number of non-anticipativity constraints (NACs). Since the reduced model is often still intractable, we discuss two special solution approaches. The first is a sequential scenario decomposition heuristic in which we sequentially solve endogenous MILP subproblems to determine the binary investment decisions, fix these decisions to satisfy the first-period and exogenous NACs, and then solve the resulting model to obtain a feasible solution. The second is Lagrangean decomposition. We present numerical results for a process network and an oilfield development planning problem. The results clearly demonstrate the efficiency of the special solution methods over solving the reduced model directly.},
author = {Apap, Robert M. and Grossmann, Ignacio E.},
doi = {10.1016/j.compchemeng.2016.11.011},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Apap, Grossmann - 2017 - Models and computational strategies for multistage stochastic programming under endogenous and exogenous uncert.pdf:pdf},
isbn = {9781510812550},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Endogenous uncertainty,Exogenous uncertainty,Lagrangean decomposition,Multistage stochastic programming,Non-anticipativity constraints,Oilfield planning},
pages = {233--274},
publisher = {Elsevier Ltd},
title = {{Models and computational strategies for multistage stochastic programming under endogenous and exogenous uncertainties}},
url = {http://dx.doi.org/10.1016/j.compchemeng.2016.11.011},
volume = {103},
year = {2017}
}
@article{Nie2018,
author = {Nie, S and Huang, Z.C. and Huang, G.H. and Yu, L and Liu, J},
doi = {10.1016/j.apenergy.2018.03.194},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Nie et al. - 2018 - Optimization of electric power systems with cost minimization and environmental-impact mitigation under multiple unc.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {electric power system,environmental impact mitigation},
month = {jul},
number = {March},
pages = {249--267},
title = {{Optimization of electric power systems with cost minimization and environmental-impact mitigation under multiple uncertainties}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0306261918305415},
volume = {221},
year = {2018}
}
@article{Raftery2017,
abstract = {Using a fully statistical approach, the paper shows that the most likely range of cumulative CO2 emissions includes the IPCC's two middle scenarios but not the extreme ones. Carbon intensity reduction should accelerate to achieve the 1.5 °C warming target.},
author = {Raftery, Adrian E. and Zimmer, Alec and Frierson, Dargan M.W. and Startz, Richard and Liu, Peiran},
doi = {10.1038/nclimate3352},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Raftery et al. - 2017 - Less than 2 °c warming by 2100 unlikely.pdf:pdf},
issn = {17586798},
journal = {Nature Climate Change},
number = {9},
pages = {637--641},
title = {{Less than 2 °c warming by 2100 unlikely}},
volume = {7},
year = {2017}
}
@article{Singham2019,
abstract = {We develop a method for finding approximate solutions to the continuous agent type principal-agent problem when analytical methods are not available. The solution is calculated by solving a discrete agent type version of the problem using sample average approximation and bootstrapping. We show how a solution to the approximate problem can be used to derive a lower bound and expected upper bound for the optimal objective function, and evaluate the error associated with the approximation. Numerical examples illustrate convergence in the approximate solution to the true solution as the number of samples increases. This works yields a method for obtaining some tractability in continuous type principal-agent problems where solutions were previously unavailable.},
author = {Singham, D. I.},
doi = {10.1016/j.ejor.2018.12.032},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Singham - 2019 - Sample average approximation for the continuous type principal-agent problem.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Mechanism design,Pricing,Principal-agent models,Sample average approximation},
number = {3},
pages = {1050--1057},
publisher = {Elsevier B.V.},
title = {{Sample average approximation for the continuous type principal-agent problem}},
url = {https://doi.org/10.1016/j.ejor.2018.12.032},
volume = {275},
year = {2019}
}
@article{Hooshmand2016,
author = {{Hooshmand Khaligh}, F. and MirHassani, S.A.},
doi = {10.1080/00207543.2015.1057625},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hooshmand Khaligh, MirHassani - 2016 - A mathematical model for vehicle routing problem under endogenous uncertainty.pdf:pdf},
issn = {0020-7543},
journal = {International Journal of Production Research},
month = {jan},
number = {2},
pages = {579--590},
title = {{A mathematical model for vehicle routing problem under endogenous uncertainty}},
url = {http://www.tandfonline.com/doi/full/10.1080/00207543.2015.1057625},
volume = {54},
year = {2016}
}
@article{Benders1962,
author = {Benders, J. F.},
doi = {10.1007/BF01386316},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Benders - 1962 - Partitioning procedures for solving mixed-variables programming problems.pdf:pdf},
issn = {0029599X},
journal = {Numerische Mathematik},
number = {1},
pages = {238--252},
title = {{Partitioning procedures for solving mixed-variables programming problems}},
volume = {4},
year = {1962}
}
@article{Alonso-Ayuso2011a,
author = {Alonso-Ayuso, Antonio and Escudero, Laureano F. and Guignard, Monique and Quinteros, Mart{\'{i}}n and Weintraub, Andres},
doi = {10.1007/s10479-009-0561-0},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Alonso-Ayuso et al. - 2011 - Forestry management under uncertainty.pdf:pdf},
issn = {0254-5330},
journal = {Annals of Operations Research},
month = {oct},
number = {1},
pages = {17--39},
title = {{Forestry management under uncertainty}},
url = {http://link.springer.com/10.1007/s10479-009-0561-0},
volume = {190},
year = {2011}
}
@article{Christian2019,
abstract = {We propose an algorithm for generating a minimum-cardinality set of non-anticipativity constraints (NAC) for scenario-based multistage-stochastic programming (MSSP) problems with both endogenous and exogenous uncertainties which allow for gradual realizations. Recently several authors have considered approaches to generate the minimum cardinality NAC set for MSSPs for various scenario set structures. However, these approaches have been limited to uncertain parameters where the realizations occur instantaneously or the full set of scenarios is required. The proposed algorithm, referred to as Sample Non-Anticipativity Constraint algorithm (SNAC) relaxes this requirement. We show that as long as the number of uncertain parameters and parameter values are kept constant, the algorithm scales polynomially in the number of scenarios.},
archivePrefix = {arXiv},
arxivId = {1908.01792},
author = {Christian, Brianna and Vinel, Alexander and Zheng, Zuo and Cremaschi, Selen},
eprint = {1908.01792},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Christian et al. - 2019 - A Graph Theoretic Approach to Non-Anticipativity Constraint Generation in Multistage Stochastic Programs with.pdf:pdf},
keywords = {endogenous uncertainty,multistage stochastic models,non-anticipativity constraints,stochastic programming},
title = {{A Graph Theoretic Approach to Non-Anticipativity Constraint Generation in Multistage Stochastic Programs with Incomplete Scenario Sets}},
url = {http://arxiv.org/abs/1908.01792},
year = {2019}
}
@article{Zhan2018,
abstract = {ABSTRACTIn this article, we study the long-term power generation investment expansion planning problem under uncertainty. We propose a bilevel optimization model that includes an upper-level multistage stochastic expansion planning problem and a collection of lower-level economic dispatch problems. This model seeks for the optimal sizing and siting for both thermal and wind power units to be built to maximize the expected profit for a profit-oriented power generation investor. To address the future uncertainties in the decision-making process, this article employs a decision-dependent stochastic programming approach. In the scenario tree, we calculate the non-stationary transition probabilities based on discrete choice theory and the economies of scale theory in electricity systems. The model is further reformulated as a single-level optimization problem and solved by decomposition algorithms. The investment decisions, computation times, and optimality of the decision-dependent model are evaluated by case...},
author = {Zhan, Yiduo and Zheng, Qipeng P.},
doi = {10.1080/24725854.2018.1442032},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Zhan, Zheng - 2018 - A multistage decision-dependent stochastic bilevel programming approach for power generation investment expansion p.pdf:pdf},
issn = {2472-5854},
journal = {IISE Transactions},
keywords = {Multistage stochastic programming,bilevel optimization,decision-dependent probability,decomposition algorithms,generation expansion},
number = {8},
pages = {720--734},
publisher = {Taylor {\&} Francis},
title = {{A multistage decision-dependent stochastic bilevel programming approach for power generation investment expansion planning}},
url = {https://www.tandfonline.com/doi/full/10.1080/24725854.2018.1442032},
volume = {50},
year = {2018}
}
@article{Hestenes1969,
author = {Hestenes, Magnus R.},
doi = {10.1007/BF00927673},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hestenes - 1969 - Multiplier and gradient methods.pdf:pdf},
issn = {0022-3239},
journal = {Journal of Optimization Theory and Applications},
month = {nov},
number = {5},
pages = {303--320},
title = {{Multiplier and gradient methods}},
url = {http://link.springer.com/10.1007/BF00927673},
volume = {4},
year = {1969}
}
@article{Watson2012,
abstract = {Although stochastic programming is a powerful tool for modeling decision-making under uncertainty, various impediments have historically prevented its wide-spread use. One factor involves the ability of non-specialists to easily express stochastic programming problems as extensions of their deterministic counterparts, which are typically formulated first. A second factor relates to the difficulty of solving stochastic programming models, particularly in the mixed-integer, non-linear, and/or multi-stage cases. Intricate, configurable, and parallel decomposition strategies are frequently required to achieve tractable run-times on large-scale problems. We simultaneously address both of these factors in our PySP software package, which is part of the Coopr open-source Python repository for optimization; the latter is distributed as part of IBM's COIN-OR repository. To formulate a stochastic program in PySP, the user specifies both the deterministic base model (supporting linear, non-linear, and mixed-integer components) and the scenario tree model (defining the problem stages and the nature of uncertain parameters) in the Pyomo open-source algebraic modeling language. Given these two models, PySP provides two paths for solution of the corresponding stochastic program. The first alternative involves passing an extensive form to a standard deterministic solver. For more complex stochastic programs, we provide an implementation of Rockafellar and Wets' Progressive Hedging algorithm. Our particular focus is on the use of Progressive Hedging as an effective heuristic for obtaining approximate solutions to multi-stage stochastic programs. By leveraging the combination of a high-level programming language (Python) and the embedding of the base deterministic model in that language (Pyomo), we are able to provide completely generic and highly configurable solver implementations. PySP has been used by a number of research groups, including our own, to rapidly prototype and solve difficult stochastic programming problems.},
author = {Watson, Jean Paul and Woodruff, David L. and Hart, William E.},
doi = {10.1007/s12532-012-0036-1},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Watson, Woodruff, Hart - 2012 - PySP Modeling and solving stochastic programs in Python.pdf:pdf},
isbn = {1867-2949},
issn = {18672949},
journal = {Mathematical Programming Computation},
keywords = {90C15,90C59,90C90},
number = {2},
pages = {109--149},
title = {{PySP: Modeling and solving stochastic programs in Python}},
volume = {4},
year = {2012}
}
@article{Pranevicius2007,
author = {Pranevicius, H. and Sutiene, K.},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pranevicius, Sutiene - 2007 - Scenario tree generation by clustering the simulated data paths.pdf:pdf},
isbn = {9780955301827},
journal = {Proceedings of 21st European Conference on Modeling and Simulation},
keywords = {k-means clustering,scenario,scenario generation,stochastic programming,tree construction},
pages = {203--208},
title = {{Scenario tree generation by clustering the simulated data paths}},
url = {http://www.scs-europe.net/conf/ecms2007/ecms2007-cd/ecms2007/ecms2007 pdf/cs{\_}0078.pdf},
year = {2007}
}
@article{SaneiBajgiran2017,
abstract = {{\textcopyright} 2016 Informa UK Limited, trading as Taylor  {\&}  Francis Group. Harvesting planning (HP) is a key tactical decision in lumber supply chains. Harvesting areas in the forests are divided into different blocks with different types and quantities of raw materials (logs). Predicting the availability of raw materials in each block along with log demand is impossible in this industry. Hence, incorporating uncertainty into the HP problem is essential in order to obtain robust plans that do not drastically fluctuate in the presence of future perturbations in the forest and log market. In this paper, we propose a robust harvesting planning model formulated based on cardinality-constrained method. The latter provides some insights into the adjustment of the level of robustness of the harvesting plan over the planning horizon and protection against uncertainty. An extensive set of experiments based on Monte-Carlo simulation is also conducted in order to better validate the proposed robust optimisation approach.},
author = {{Sanei Bajgiran}, Omid and {Kazemi Zanjani}, Masoumeh and Nourelfath, Mustapha},
doi = {10.1080/00207543.2016.1213915},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Sanei Bajgiran, Kazemi Zanjani, Nourelfath - 2017 - Forest harvesting planning under uncertainty a cardinality-constrained approach.pdf:pdf},
issn = {1366588X},
journal = {International Journal of Production Research},
keywords = {cardinality-constrained method,harvesting planning,lumber supply chain,uncertain supply and demand},
number = {7},
pages = {1914--1929},
publisher = {Taylor {\&} Francis},
title = {{Forest harvesting planning under uncertainty: a cardinality-constrained approach}},
url = {http://dx.doi.org/10.1080/00207543.2016.1213915},
volume = {55},
year = {2017}
}
@incollection{Kucukyavuz2017,
author = {K{\"{u}}{\c{c}}{\"{u}}kyavuz, Simge and Sen, Suvrajeet},
booktitle = {The Operations Research Revolution},
doi = {10.1287/educ.2017.0171},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/K{\"{u}}{\c{c}}{\"{u}}kyavuz, Sen - 2017 - An Introduction to Two-Stage Stochastic Mixed-Integer Programming.pdf:pdf},
isbn = {9780990615309},
month = {sep},
number = {October},
pages = {1--27},
publisher = {INFORMS},
title = {{An Introduction to Two-Stage Stochastic Mixed-Integer Programming}},
url = {http://pubsonline.informs.org/doi/10.1287/educ.2017.0171},
year = {2017}
}
@article{Schutz2009,
abstract = {We present a supply chain design problem modeled as a sequence of splitting and combining processes. We formulate the problem as a two-stage stochastic program. The first-stage decisions are strategic location decisions, whereas the second stage consists of operational decisions. The objective is to minimize the sum of investment costs and expected costs of operating the supply chain. In particular the model emphasizes the importance of operational flexibility when making strategic decisions. For that reason short-term uncertainty is considered as well as long-term uncertainty. The real-world case used to illustrate the model is from the Norwegian meat industry. We solve the problem by sample average approximation in combination with dual decomposition. Computational results are presented for different sample sizes and different levels of data aggregation in the second stage. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Sch{\"{u}}tz, Peter and Tomasgard, Asgeir and Ahmed, Shabbir},
doi = {10.1016/j.ejor.2008.11.040},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Sch{\"{u}}tz, Tomasgard, Ahmed - 2009 - Supply chain design under uncertainty using sample average approximation and dual decomposition.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Dual decomposition,Sample average approximation,Stochastic programming,Supply chain design},
number = {2},
pages = {409--419},
publisher = {Elsevier B.V.},
title = {{Supply chain design under uncertainty using sample average approximation and dual decomposition}},
url = {http://dx.doi.org/10.1016/j.ejor.2008.11.040},
volume = {199},
year = {2009}
}
@article{Hou2019,
abstract = {In this paper, the potential benefits of quasi-Monte Carlo (QMC) methods for uncertainty propagation are assessed via two applications: a numerical case study and a realistic and complex building physical case study. The sampling efficiency of four quasi-Monte Carlo sampling strategies — Optimized Latin hypercube, Sobol' sequence, Niederreiter–Xing sequence and lattice sequence — are quantified and the errors of these quasi-Monte Carlo methods are estimated. In addition, for getting a better understanding of the potential factors that may influence the performance of quasi-Monte Carlo methods, the effect of the different parameters and the smoothness of the target function for the building physical case study are investigated for two quantities of interest. A sensitivity analysis is performed in which first and total order Sobol' indices are calculated and a kernel smoother is used to show the effect on the quantity of interest for certain input parameters. The outcomes show that quasi-Monte Carlo methods perform at least as well as the Monte Carlo method and are capable of outperforming the standard Monte Carlo method if the target function is sufficiently smooth and mainly depends on a limited number of parameters.},
author = {Hou, Tianfeng and Nuyens, Dirk and Roels, Staf and Janssen, Hans},
doi = {10.1016/j.ress.2019.106549},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hou et al. - 2019 - Quasi-Monte Carlo based uncertainty analysis Sampling efficiency and error estimation in engineering applications.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Building performance,Error estimation,Kernel smoother,Quasi-Monte carlo,Sampling efficiency,Sensitivity analysis,Sobol' Indices,Uncertainty propagation},
number = {May},
pages = {106549},
publisher = {Elsevier Ltd},
title = {{Quasi-Monte Carlo based uncertainty analysis: Sampling efficiency and error estimation in engineering applications}},
url = {https://doi.org/10.1016/j.ress.2019.106549},
volume = {191},
year = {2019}
}
@article{Hooshmand2018,
author = {Hooshmand, F. and MirHassani, S. A.},
doi = {10.1007/s00186-017-0600-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hooshmand, MirHassani - 2018 - Reduction of nonanticipativity constraints in multistage stochastic programming problems with endogenous.pdf:pdf},
issn = {14325217},
journal = {Mathematical Methods of Operations Research},
keywords = {Constraint reduction,Endogenous and exogenous uncertainties,Multistage stochastic programming,Redundant nonanticipativity constraints},
number = {1},
title = {{Reduction of nonanticipativity constraints in multistage stochastic programming problems with endogenous and exogenous uncertainty}},
volume = {87},
year = {2018}
}
@article{Watson2011,
abstract = {Numerous planning problems can be formulated as multi-stage stochastic programs and many possess key discrete (integer) decision variables in one or more of the stages. Progressive hedging (PH) is a scenario-based decomposition technique that can be leveraged to solve such problems. Originally devised for problems possessing only continuous variables, PH has been successfully applied as a heuristic to solve multi-stage stochastic programs with integer variables. However, a variety of critical issues arise in practice when implementing PH for the discrete case, especially in the context of very difficult or large-scale mixed-integer problems. Failure to address these issues properly results in either non-convergence of the heuristic or unacceptably long run-times. We investigate these issues and describe algorithmic innovations in the context of a broad class of scenario-based resource allocation problem in which decision variables represent resources available at a cost and constraints enforce the need for sufficient combinations of resources. The necessity and efficacy of our techniques is empirically assessed on a two-stage stochastic network flow problem with integer variables in both stages.},
author = {Watson, Jean Paul and Woodruff, David L.},
doi = {10.1007/s10287-010-0125-4},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Watson, Woodruff - 2011 - Progressive hedging innovations for a class of stochastic mixed-integer resource allocation problems.pdf:pdf},
issn = {1619697X},
journal = {Computational Management Science},
number = {4},
pages = {355--370},
title = {{Progressive hedging innovations for a class of stochastic mixed-integer resource allocation problems}},
volume = {8},
year = {2011}
}
@article{Rockafellar1977,
author = {Rockafellar, R},
doi = {10.1016/0022-247X(77)90020-8},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Rockafellar - 1977 - Measures as Lagrange multipliers in multistage stochastic programming.pdf:pdf},
issn = {0022247X},
journal = {Journal of Mathematical Analysis and Applications},
number = {2},
pages = {301--313},
title = {{Measures as Lagrange multipliers in multistage stochastic programming}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022247X77900208},
volume = {60},
year = {1977}
}
@book{Bertsimas2018,
abstract = {In recent years, decision rules have been established as the preferred solution method for addressing computationally demanding, multistage adaptive optimization problems. Despite their success, existing decision rules (a) are typically constrained by their a priori design and (b) do not incorporate in their modeling adaptive binary decisions. To address these problems, we first derive the structure for optimal decision rules involving continuous and binary variables as piecewise linear and piecewise constant functions, respectively. We then propose a methodology for the optimal design of such decision rules that have a finite number of pieces and solve the problem robustly using mixed-integer optimization. We demonstrate the effectiveness of the proposed methods in the context of two multistage inventory control problems. We provide global lower bounds and show that our approach is (i) practically tractable and (ii) provides high quality solutions that outperform alternative methods.},
author = {Bertsimas, Dimitris and Georghiou, Angelos},
booktitle = {Mathematical Programming},
doi = {10.1007/s10107-017-1135-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Bertsimas, Georghiou - 2018 - Binary decision rules for multistage adaptive mixed-integer optimization.pdf:pdf},
isbn = {10.1287/opre.2015.1365},
issn = {14364646},
keywords = {Adaptive optimization,Binary decision rules,Mixed-integer optimization},
number = {2},
pages = {395--433},
publisher = {Springer Berlin Heidelberg},
title = {{Binary decision rules for multistage adaptive mixed-integer optimization}},
volume = {167},
year = {2018}
}
@article{Mijangos2016,
abstract = {{\textcopyright} 2016 Vilnius University. We present an algorithm to solve multistage stochastic convex problems, whose objective function and constraints are nonlinear. It is based on the twin-node-family concept involved in the Branch-and-Fix Coordination method. These problems have 0-1 mixed-integer and continuous variables in all the stages. The non-anticipativity constraints are satisfied by means of the twin-node-family strategy. In this work to solve each nonlinear convex subproblem at each node we propose the solution of sequences of quadratic subproblems. Due to the convexity of the constraints we can approximate them by means of outer approximations. These methods have been implemented in C++ with the help of CPLEX 12.1, which only solves the quadratic approximations. The test problems have been randomly generated by using a C++ code developed by this author. Numerical experiments have been performed and its efficiency has been compared with that of a well-known code.},
author = {Mijangos, Eugenio},
doi = {10.15388/Informatica.2016.112},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Mijangos - 2016 - Solving Multistage Mixed Nonlinear Convex Stochastic Problems.pdf:pdf},
issn = {08684952},
journal = {Informatica},
keywords = {branch and fix coordination,convex programming,integer nonlinear programming,mixed,outer approximation,quadratic programming,stochastic programming},
number = {4},
pages = {799--818},
title = {{Solving Multistage Mixed Nonlinear Convex Stochastic Problems}},
volume = {27},
year = {2016}
}
@article{Guan2011,
author = {Guan, Z and Philpott, A.B.},
doi = {10.1016/j.ijpe.2009.11.003},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Guan, Philpott - 2011 - A multistage stochastic programming model for the New Zealand dairy industry.pdf:pdf},
issn = {09255273},
journal = {International Journal of Production Economics},
keywords = {Decomposition,Multistage stochastic quadratic programming,Price-demand curve,Sampling,Uncertain supply,multistage stochastic quadratic},
month = {dec},
number = {2},
pages = {289--299},
publisher = {Elsevier},
title = {{A multistage stochastic programming model for the New Zealand dairy industry}},
url = {http://dx.doi.org/10.1016/j.ijpe.2009.11.003 https://linkinghub.elsevier.com/retrieve/pii/S0925527309004058},
volume = {134},
year = {2011}
}
@article{Escudero2018a,
abstract = {In this work a modeling framework and a solution approach have been presented for a multi-period stochastic mixed 0–1 problem arising in tactical supply chain planning (TSCP). A multistage scenario tree based scheme is used to represent the parameters' uncertainty and develop the related Deterministic Equivalent Model. A cost risk reduction is performed by using a new time-consistent risk averse measure. Given the dimensions of this problem in real-life applications, a decomposition approach is proposed. It is based on stochastic dynamic programming (SDP). The computational experience is twofold, a comparison is performed between the plain use of a current state-of-the-art mixed integer optimization solver and the proposed SDP decomposition approach considering the risk neutral version of the model as the subject for the benchmarking. The add-value of the new risk averse strategy is confirmed by the computational results that are obtained using SDP for both versions of the TSCP model, namely, risk neutral and risk averse.},
author = {Escudero, Laureano F. and Monge, Juan Francisco and Morales, Dolores Romero},
doi = {10.1016/j.cor.2017.07.011},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Escudero, Monge, Morales - 2018 - On the time-consistent stochastic dominance risk averse measure for tactical supply chain planning und.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Multistage stochastic integer optimization,Nonlinear separable objective function,Risk management,Stochastic nested decomposition,Tactical supply chain planning,Time-consistency},
pages = {270--286},
publisher = {Elsevier Ltd},
title = {{On the time-consistent stochastic dominance risk averse measure for tactical supply chain planning under uncertainty}},
url = {http://dx.doi.org/10.1016/j.cor.2017.07.011},
volume = {100},
year = {2018}
}
@article{Li2019,
author = {Li, Jinshu and Zhu, Feilin and Xu, Bin and Yeh, William W.-G.},
doi = {10.1016/j.jhydrol.2019.123943},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Li et al. - 2019 - Streamflow scenario tree reduction based on conditional Monte Carlo sampling and regularized optimization.pdf:pdf},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {Monte Carlo sampling,Regularized optimization,Reservoir operation,Scenario tree reduction,Streamflow scenario tree generation,regularized optimization,scenario tree reduction,stream fl ow scenario,tree generation},
number = {May},
pages = {123943},
publisher = {Elsevier},
title = {{Streamflow scenario tree reduction based on conditional Monte Carlo sampling and regularized optimization}},
url = {https://doi.org/10.1016/j.jhydrol.2019.123943},
volume = {577},
year = {2019}
}
@article{Barro2016,
author = {Barro, Diana and Canestrelli, Elio},
doi = {10.1007/s00291-015-0427-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Barro, Canestrelli - 2016 - Combining stochastic programming and optimal control to decompose multistage stochastic optimization problem.pdf:pdf},
issn = {14366304},
journal = {OR Spectrum},
keywords = {Decomposition methods,Discrete time control,Iterative scheme,Stochastic programming},
number = {3},
pages = {711--742},
publisher = {Springer Berlin Heidelberg},
title = {{Combining stochastic programming and optimal control to decompose multistage stochastic optimization problems}},
volume = {38},
year = {2016}
}
@article{Santos2017,
abstract = {Several optimization strategies are suitable for parallel processing, such as mathematical-programming based decomposition strategies, like Lagrangian relaxation and two-stage Benders decomposition, and evolutionary programming-like algorithms. In such cases, most subproblems can be solved independently by different processors. However, parallel processing is not suitable for some problems solved by nested Benders decomposition, due to the hierarchy between subproblems related to different time steps. In particular, for the deterministic case, parallel programming has been restricted to thread processing in lower-level machine computation and optimization solver codes. This paper proposes a new nested Benders decomposition strategy that is suitable for parallel processing, where time-coupled stages are solved simultaneously and an alternative procedure is employed to share initial conditions for the next stages as well as Benders cuts for the previous stages. The methodology is applied to the deterministic short term hydrothermal scheduling problem for the real large-scale Brazilian system, where the advantages of the proposed approach become more evident. In order to show the applicability of the method in low-budget and small parallel environments, the case study was processed with up to 24 process on multi-core computers.},
author = {Santos, Tiago Norbiato and Diniz, Andre Luiz and Borges, Carmen Lucia Tancredo},
doi = {10.1109/TSG.2016.2593402},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Santos, Diniz, Borges - 2017 - A new nested benders decomposition strategy for parallel processing applied to the hydrothermal schedulin.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Multi stage Benders decomposition,Parallel processing,Short term hydrothermal scheduling},
number = {3},
pages = {1504--1512},
title = {{A new nested benders decomposition strategy for parallel processing applied to the hydrothermal scheduling problem}},
volume = {8},
year = {2017}
}
@article{Piazza2014,
abstract = {In this paper we study the exploitation of a one species forest plantation when timber price is governed by a stochastic process. The work focuses on providing closed expressions for the optimal harvesting policy in terms of the parameters of the price process and the discount factor, with finite and infinite time horizon. We assume that harvest is restricted to mature trees older than a certain age and that growth and natural mortality after maturity are neglected. We use stochastic dynamic programming techniques to characterize the optimal policy and we model price using a geometric Brownian motion and an Ornstein-Uhlenbeck process. In the first case we completely characterize the optimal policy for all possible choices of the parameters. In the second case we provide sufficient conditions, based on explicit expressions for reservation prices, assuring that harvesting everything available is optimal. In addition, for the Ornstein-Uhlenbeck case we propose a policy based on a reservation price that performs well in numerical simulations. In both cases we solve the problem for every initial condition and the best policy is obtained endogenously, that is, without imposing any ad hoc restrictions such as maximum sustained yield or convergence to a predefined final state. {\textcopyright} 2014 Springer Science+Business Media New York.},
author = {Piazza, Adriana and Pagnoncelli, Bernardo K.},
doi = {10.1007/s10479-014-1559-9},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Piazza, Pagnoncelli - 2014 - The optimal harvesting problem under price uncertainty.pdf:pdf},
issn = {15729338},
journal = {Annals of Operations Research},
keywords = {Forest management,Optimal harvesting,Price uncertainty,Stochastic dynamic programming},
number = {1},
pages = {425--445},
title = {{The optimal harvesting problem under price uncertainty}},
volume = {217},
year = {2014}
}
@article{Apap2017a,
abstract = {In this work, we address the modeling and solution of mixed-integer linear multistage stochastic programming problems involving both endogenous and exogenous uncertain parameters. We first propose a composite scenario tree that captures both types of uncertainty, and we exploit its unique structure to derive new theoretical properties that can drastically reduce the number of non-anticipativity constraints (NACs). Since the reduced model is often still intractable, we discuss two special solution approaches. The first is a sequential scenario decomposition heuristic in which we sequentially solve endogenous MILP subproblems to determine the binary investment decisions, fix these decisions to satisfy the first-period and exogenous NACs, and then solve the resulting model to obtain a feasible solution. The second is Lagrangean decomposition. We present numerical results for a process network and an oilfield development planning problem. The results clearly demonstrate the efficiency of the special solution methods over solving the reduced model directly.},
author = {Apap, Robert M. and Grossmann, Ignacio E.},
doi = {10.1016/j.compchemeng.2016.11.011},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Apap, Grossmann - 2017 - Models and computational strategies for multistage stochastic programming under endogenous and exogenous unc(2).pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Endogenous uncertainty,Exogenous uncertainty,Lagrangean decomposition,Multistage stochastic programming,Non-anticipativity constraints,Oilfield planning},
number = {July},
pages = {233--274},
title = {{Models and computational strategies for multistage stochastic programming under endogenous and exogenous uncertainties}},
volume = {103},
year = {2017}
}
@article{Andalaft2003,
abstract = {We consider a problem of forest planning on pine plantations over a two to five year horizon. Basic decisions concern the areas to harvest in each period, the amount of timber to produce to satisfy aggregate demands for log exports, sawmills and pulp plants, and the roads to build for access and storage of timber. A linear programming model with 0–1variables describes the decision process. Solution strategies involve strengthening of the model, lifting some of the constraints, and applying Lagrangean relaxation. Results on real planning problems show that even as these problems become more complex, the proposed solution strategies lead to very good solutions, reducing the residual gap for the most difficult data set from 162{\%} to 1.6{\%}, and for all data sets to 2.6{\%} or less. Received July 1999; revisions received November 2001, February 2002; accepted August 2002. Subject classifications: Programming, integer: integer programming model for forest harvesting. Programming, integer, relaxation: use of Lagrangean relaxation in forestry model. Transportation, models, network: design road network for forest harvesting.},
author = {Andalaft, Nicolas and Andalaft, Pablo and Guignard, Monique and Magendzo, Adrian and Wainer, Alexis and Weintraub, Andres},
doi = {10.1287/opre.51.4.613.16107},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Andalaft et al. - 2003 - A Problem of Forest Harvesting and Road Building Solved Through Model Strengthening and Lagrangean Relaxation.pdf:pdf},
isbn = {0030364X},
issn = {0030-364X},
journal = {Operations Research},
number = {4},
pages = {613--628},
title = {{A Problem of Forest Harvesting and Road Building Solved Through Model Strengthening and Lagrangean Relaxation}},
volume = {51},
year = {2003}
}
@article{Feizollahi2017,
abstract = {We investigate the augmented Lagrangian dual (ALD) for mixed integer linear programming (MIP) problems. ALD modifies the classical Lagrangian dual by appending a nonlinear penalty function on the violation of the dualized constraints in order to reduce the duality gap. We first provide a primal characterization for ALD for MIPs and prove that ALD is able to asymptotically achieve zero duality gap when the weight on the penalty function is allowed to go to infinity. This provides an alternative characterization and proof of a recent result in Boland and Eberhard (Math Program 150(2):491–509, 2015, Proposition 3). We further show that, under some mild conditions, ALD using any norm as the augmenting function is able to close the duality gap of an MIP with a finite penalty coefficient. This generalizes the result in Boland and Eberhard (2015, Corollary 1) from pure integer programming problems with bounded feasible region to general MIPs. We also present an example where ALD with a quadratic augmenting function is not able to close the duality gap for any finite penalty coefficient.},
annote = {The existence of a proximal subgradient at ¯
u corresponds to the existence of a ‘local
quadratic support' to f at},
author = {Feizollahi, Mohammad Javad and Ahmed, Shabbir and Sun, Andy},
doi = {10.1007/s10107-016-1012-8},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Feizollahi, Ahmed, Sun - 2017 - Exact augmented Lagrangian duality for mixed integer linear programming.pdf:pdf},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {Lagrangian duality,Mixed integer linear programming,Penalty functions},
number = {1-2},
pages = {365--387},
publisher = {Springer Berlin Heidelberg},
title = {{Exact augmented Lagrangian duality for mixed integer linear programming}},
volume = {161},
year = {2017}
}
@article{Pereira1991,
abstract = {This paper presents a methodology for the solution of multistage stochastic optimization problems, based on the approximation of the expected-cost-to-go functions of stochastic dynamic programming by piecewise linear functions. No state discretization is necessary, and the combinatorial "explosion" with the number of states (the well known "curse of dimensionality" of dynamic programming) is avoided. The piecewise functions are obtained from the dual solutions of the optimization problem at each stage and correspond to Benders cuts in a stochastic, multistage decomposition framework. A case study of optimal stochastic scheduling for a 39-reservoir system is presented and discussed. {\textcopyright} 1991 The Mathematical Programming Society, Inc.},
author = {Pereira, M. V.F. and Pinto, L. M.V.G.},
doi = {10.1007/BF01582895},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pereira, Pinto - 1991 - Multi-stage stochastic optimization applied to energy planning.pdf:pdf},
issn = {00255610},
journal = {Mathematical Programming},
number = {1-3},
pages = {359--375},
title = {{Multi-stage stochastic optimization applied to energy planning}},
volume = {52},
year = {1991}
}
@article{Seguin2017,
abstract = {This paper presents an optimization approach to solve the short-term hydropower unit commitment and loading problem with uncertain inflows. A scenario tree is built based on a forecasted fan of inflows, which is developed using the weather forecast and the historical weather realizations. The tree-building approach seeks to minimize the nested distance between the stochastic process of historical inflow data and the multistage stochastic process represented in the scenario tree. A two-phase multistage stochastic model is used to solve the problem. The proposed approach is tested on a 31 day rolling-horizon with daily forecasted inflows for three power plants situated in the province of Quebec, Canada, that belong to the company Rio Tinto.},
author = {S{\'{e}}guin, Sara and Fleten, Stein Erik and C{\^{o}}t{\'{e}}, Pascal and Pichler, Alois and Audet, Charles},
doi = {10.1016/j.ejor.2016.11.028},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/S{\'{e}}guin et al. - 2017 - Stochastic short-term hydropower planning with inflow scenario trees.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Large scale optimization,Nonlinear programming,OR in energy,Scenarios,Stochastic programming},
number = {3},
pages = {1156--1168},
title = {{Stochastic short-term hydropower planning with inflow scenario trees}},
volume = {259},
year = {2017}
}
@article{Morton2006,
author = {Bayraksan, G{\"{u}}zin and Morton, David P},
doi = {10.1007/s10107-006-0720-x},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Bayraksan, Morton/Mathematical Programming/Bayraksan, Morton - 2006 - Assessing solution quality in stochastic programs.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
month = {sep},
number = {2-3},
pages = {495--514},
title = {{Assessing solution quality in stochastic programs}},
url = {http://link.springer.com/10.1007/s10107-006-0720-x},
volume = {108},
year = {2006}
}
@article{Gupta2014,
abstract = {We introduce a multiple scenario, multiple period, optimization-based decision support system (DSS) for strategic planning in a process industry. The DSS is based on a two stage stochastic linear program (SLP) with recourse for strategic planning. The model can be used with little or no knowledge of Management Sciences. The model maximizes the expected contribution (to profit), subject to constraints of material balance, facility capacity, facility input, facility output, inventory balance constraints, and additional constraints for non-anticipativity. We describe the database structure for a SLP based DSS in contrast to the deterministic linear programming (LP) based DSS. In the second part of this paper, we compare a completely relational database structure with a hierarchical one using multiple criteria. We demonstrate that by using completely relational databases, the efficiency of model generation can be improved by 60{\%} compared to hierarchical databases. {\textcopyright} 2014 Elsevier B.V.},
author = {Gupta, Narain and Dutta, Goutam and Fourer, Robert},
doi = {10.1016/j.dss.2014.04.003},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Gupta, Dutta, Fourer - 2014 - An expanded database structure for a class of multi-period, stochastic mathematical programming models for.pdf:pdf},
isbn = {0167-9236},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Database structure,Decision support system,Management science,Optimization,Process industries,Stochastic programming (SLP)},
pages = {43--56},
publisher = {Elsevier B.V.},
title = {{An expanded database structure for a class of multi-period, stochastic mathematical programming models for process industries}},
url = {http://dx.doi.org/10.1016/j.dss.2014.04.003},
volume = {64},
year = {2014}
}
@article{Kaut2007,
author = {Kaut, Michal and Wallace, Stein W},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Kaut, Wallace - 2007 - Evaluation of scenario-generation methods for stochastic programming.pdf:pdf},
journal = {Pacific Journal of Optimization},
keywords = {scenario generation,scenario tree,stochastic programming},
number = {2},
pages = {257--271},
title = {{Evaluation of scenario-generation methods for stochastic programming}},
url = {http://www.math.ntnu.no/{~}hek/OptimeringVK/Wallace/EvaluationKautWallace.pdf},
volume = {3},
year = {2007}
}
@article{Hart2009,
abstract = {We describe Pyomo, an open-source tool for modeling optimization applications in Python. Pyomo can be used to define abstract problems, create concrete problem instances, and solve these instances with standard solvers. Pyomo provides a capability that is commonly associated with algebraic modeling languages like AMPL and GAMS. Pyomo leverages the capabilities of the Coopr software, which integrates Python packages for defining optimizers, modeling optimization applications, and managing computational experiments.},
author = {Hart, William E.},
doi = {10.1007/978-0-387-88843-9_1},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hart - 2009 - Python optimization modeling objects (Pyomo).pdf:pdf},
isbn = {978-0-387-88842-2},
issn = {1387666X},
journal = {Operations Research/ Computer Science Interfaces Series},
keywords = {Modeling language,Open source software,Optimization,Python},
pages = {3--19},
title = {{Python optimization modeling objects (Pyomo)}},
volume = {47},
year = {2009}
}
@article{Hochreiter2007,
abstract = {The quality of multi-stage stochastic optimization models as they appear in asset liability management, energy planning, transportation, supply chain management, and other applications depends heavily on the quality of the underlying scenario model, describing the uncertain processes influencing the profit/cost function, such as asset prices and liabilities, the energy demand process, demand for transportation, and the like. A common approach to generate scenarios is based on estimating an unknown distribution and matching its moments with moments of a discrete scenario model. This paper demonstrates that the problem of finding valuable scenario approximations can be viewed as the problem of optimally approximating a given distribution with some distance function. We show that for Lipschitz continuous cost/profit functions it is best to employ the Wasserstein distance. The resulting optimization problem can be viewed as a multi-dimensional facility location problem, for which at least good heuristic algorithms exist. For multi-stage problems, a scenario tree is constructed as a nested facility location problem. Numerical convergence results for financial mean-risk portfolio selection conclude the paper. [PUBLICATION ABSTRACT]},
author = {Hochreiter, Ronald and Pflug, Georg Ch},
doi = {10.1007/s10479-006-0140-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hochreiter, Pflug - 2007 - Financial scenario generation for stochastic multi-stage decision processes as facility location problems.pdf:pdf},
issn = {02545330},
journal = {Annals of Operations Research},
keywords = {Multi-stage financial scenario generation,Stochastic programming},
number = {1},
pages = {257--272},
title = {{Financial scenario generation for stochastic multi-stage decision processes as facility location problems}},
volume = {152},
year = {2007}
}
@article{Mikhailov2000,
author = {Mikhailov, Sergei A.},
doi = {10.1016/s1474-6670(17)38023-0},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Mikhailov - 2000 - Application of stochastic optimization to options pricing.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Financial systems,stochastic control,discrete-time,analytical and numerical simulation,discrete-time systems,feedback control,financial systems,methods,stochastic control},
number = {20},
pages = {43--48},
publisher = {Elsevier},
title = {{Application of stochastic optimization to options pricing}},
url = {http://dx.doi.org/10.1016/S1474-6670(17)38023-0},
volume = {33},
year = {2000}
}
@article{Gade2016,
author = {Gade, Dinakar and Hackebeil, Gabriel and Ryan, Sarah M. and Watson, Jean-Paul and Wets, Roger J.-B. and Woodruff, David L.},
doi = {10.1007/s10107-016-1000-z},
issn = {0025-5610},
journal = {Mathematical Programming},
month = {may},
number = {1},
pages = {47--67},
title = {{Obtaining lower bounds from the progressive hedging algorithm for stochastic mixed-integer programs}},
url = {http://link.springer.com/10.1007/s10107-016-1000-z},
volume = {157},
year = {2016}
}
@article{Boland2019,
author = {Boland, Natashia and Christiansen, Jeffrey and Dandurand, Brian and Eberhard, Andrew and Oliveira, Fabricio},
doi = {10.1007/s10107-018-1253-9},
issn = {0025-5610},
journal = {Mathematical Programming},
month = {may},
number = {1-2},
pages = {503--536},
title = {{A parallelizable augmented Lagrangian method applied to large-scale non-convex-constrained optimization problems}},
url = {http://link.springer.com/10.1007/s10107-018-1253-9},
volume = {175},
year = {2019}
}
@article{Atakan2018,
abstract = {Progressive Hedging (PH) is a well-known algorithm for solving multi-stage stochastic convex optimization problems. Most previous extensions of PH for stochastic mixed-integer programs have been implemented without convergence guarantees. In this paper, we present a new framework that shows how PH can be utilized while guaranteeing convergence to globally optimal solutions of stochastic mixed-integer convex programs. We demonstrate the effectiveness of the proposed frame-work through computational experiments.},
author = {Atakan, Semih and Sen, Suvrajeet},
doi = {10.1007/s10287-018-0311-3},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Atakan, Sen - 2018 - A Progressive Hedging based branch-and-bound algorithm for mixed-integer stochastic programs.pdf:pdf},
isbn = {9550151026},
issn = {1619-697X},
journal = {Computational Management Science},
keywords = {progressive hedging},
month = {oct},
number = {3-4},
pages = {501--540},
title = {{A Progressive Hedging based branch-and-bound algorithm for mixed-integer stochastic programs}},
url = {http://link.springer.com/10.1007/s10287-018-0311-3},
volume = {15},
year = {2018}
}
@article{Zhou2019,
abstract = {The increasing share of variable renewable energy sources and the improving requirements on system security and reliability are calling for important changes in the integrated energy systems. Hence this paper proposes a multi-stage contingency-constrained co-planning model for electricity-gas systems interconnected with gas-fired units and power-to-gas plants considering the uncertainties of load demand and wind power. The proposed model considers the long-term co-planning for electricity-gas systems with the short-term operation constraints and N-1 reliability criterion, which is formulated as a mixed-integer linear programming problem. First, a scenario reduction method based on affinity propagation clustering is utilized to handle the uncertainties. Afterwards, the N-1 criterion is tackled by a contingency screening method based on line outage distribution factors. Finally, an iterative Benders decomposition method is developed to divide the programming problem into one master investment problem and three subproblems. The iterative process will continue between master problem and each subproblem until an economic, reliable and fuel-supply feasible solution is obtained. In order to verify the feasibility of the proposed model and the effectiveness of the proposed method, case studies are conducted on two different scales of electricity-gas systems.},
author = {Zhou, Huansheng and Zheng, J. H. and Li, Zhigang and Wu, Q. H. and Zhou, X. X.},
doi = {10.1016/j.energy.2019.05.119},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Zhou et al. - 2019 - Multi-stage contingency-constrained co-planning for electricity-gas systems interconnected with gas-fired units and.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {Affinity propagation clustering,Electricity-gas systems,Iterative Benders decomposition,Line outage distribution factors,Power-to-gas plants,Renewable energy sources},
pages = {689--701},
title = {{Multi-stage contingency-constrained co-planning for electricity-gas systems interconnected with gas-fired units and power-to-gas plants using iterative Benders decomposition}},
volume = {180},
year = {2019}
}
@article{Escudero2018,
abstract = {A preparedness resource allocation model and an algorithmic approach are presented for a three-stage stochastic problem for managing natural disaster mitigation. That preparedness consists of warehouse location and capacity assignment and the procurement of commodities on the one hand and refurbishing the rescue network infrastructure on the other. Two types of uncertainty are considered: exogenous uncertainty which is due to the lack of full knowledge about the probability and intensity of the disaster for each focal point in a given network; and endogenous uncertainty which is based on the decision-maker's investment to obtain greater accuracy in regard to the occurrence of the disaster and to reinforcing the network infrastructure. A stochastic mixed 0-1 bilinear optimization model is presented. Additionally, a time-consistent stochastic dominance-based risk-averse measure for a set of profiles in a multifunction setting is introduced. Both types of elements imply large-sized problems, so some kind of decomposition algorithmic should be used. Based on the special features of the three-stage problem subject of this work, we introduce the Cluster Dual Descent Algorithm for obtaining feasible solutions based on duality theory. Computational results are reported for a well-known real-life case by comparing the performance of the models based on the alternatives given by the risk-neutral and risk-averse versions jointly with exogenous and endogenous uncertainty.},
author = {Escudero, Laureano F. and Gar{\'{i}}n, M. Araceli and Monge, Juan F. and Unzueta, Aitziber},
doi = {10.1016/j.cor.2018.05.010},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Escudero et al. - 2018 - On preparedness resource allocation planning for natural disaster relief under endogenous uncertainty with time.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Decomposition algorithm,Exogenous and endogenous uncertainties,Mixed 0-1 bilinear optimization,OR on disaster relief,Risk-averse,Time-consistent stochastic dominance functional},
pages = {84--102},
title = {{On preparedness resource allocation planning for natural disaster relief under endogenous uncertainty with time-consistent risk-averse management}},
volume = {98},
year = {2018}
}
@article{Alvarez-Miranda2018,
abstract = {We propose a multicriteria decision-making framework to support strategic decisions in forest management, taking into account uncertainty due to climate change and sustainability goals. In our setting, uncertainty is modeled by means of climate change scenarios. The decision task is to define a harvest scheduling that addresses, simultaneously, conflicting objectives: the economic value of the strategy, the carbon sequestration, the water use efficiency for biomass production and the runoff water, during the whole planning horizon. While the first objective is a classical managerial one, the later tree objectives aim at ensuring the environmental sustainability of the forest management plan. The proposed framework is a combination of Goal Programming and Stochastic Programming. Depending on the decision-maker preferences, the model produces harvest scheduling policies that yield different trade-offs among the conflicting criteria. Furthermore, we propose the incorporation of a risk-averse component in order to improve the performance of the obtained policies with respect to their economical value. This novel approach is tested on a real forest, located in central Portugal, which is comprised of a large number of stands (aggregated into 21 strata), climate change is modeled by 32 scenarios, and a planning horizon of 15 years is considered. The obtained results show the capacity of the designed framework to provide a pool of diverse solutions with different trade-offs among the four criteria, giving to the manager the possibility of choosing a harvesting policy that meets her/his requirements.},
author = {{\'{A}}lvarez-Miranda, Eduardo and Garcia-Gonzalo, Jordi and Ulloa-Fierro, Felipe and Weintraub, Andr{\'{e}}s and Barreiro, Susana},
doi = {10.1016/j.ejor.2017.04.052},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/{\'{A}}lvarez-Miranda et al. - 2018 - A multicriteria optimization model for sustainable forest management under climate change uncertainty An.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Forestry management,Multicriteria optimization,OR in environment and climate change,Stochastic Programming,Sustainability},
number = {1},
pages = {79--98},
title = {{A multicriteria optimization model for sustainable forest management under climate change uncertainty: An application in Portugal}},
volume = {269},
year = {2018}
}
@article{Balezentis2017,
abstract = {Integrated Assessment Models (IAMs) are omnipresent in energy policy analysis. Even though IAMs can successfully handle uncertainty pertinent to energy planning problems, they render multiple variables as outputs of the modelling. Therefore, policy makers are faced with multiple energy development scenarios and goals. Specifically, technical, environmental, and economic aspects are represented by multiple criteria, which, in turn, are related to conflicting objectives. Preferences of decision makers need to be taken into account in order to facilitate effective energy planning. Multi-criteria decision making (MCDM) tools are relevant in aggregating diverse information and thus comparing alternative energy planning options. The paper aims at ranking European Union (EU) energy development scenarios based on several IAMs with respect to multiple criteria. By doing so, we account for uncertainty surrounding policy priorities outside the IAM. In order to follow a sustainable approach, the ranking of policy options is based on EU energy policy priorities: energy efficiency improvements, increased use of renewables, reduction in and low mitigations costs of GHG emission. The ranking of scenarios is based on the estimates rendered by the two advanced IAMs relying on different approaches, namely TIAM and WITCH. The data are fed into the three MCDM techniques: the method of weighted aggregated sum/product assessment (WASPAS), the Additive Ratio Assessment (ARAS) method, and technique for order preference by similarity to ideal solution (TOPSIS). As MCDM techniques allow assigning different importance to objectives, a sensitivity analysis is carried out to check the impact of perturbations in weights upon the final ranking. The rankings provided for the scenarios by different MCDM techniques diverge, first of all, due to the underlying assumptions of IAMs. Results of the analysis provide valuable insights in integrated application of both IAMs and MCDM models for developing energy policy scenarios and decision making in energy sector.},
author = {Bale{\v{z}}entis, Tomas and Streimikiene, Dalia},
doi = {10.1016/j.apenergy.2016.10.085},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Bale{\v{z}}entis, Streimikiene - 2017 - Multi-criteria ranking of energy generation scenarios with Monte Carlo simulation.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {EU energy policy priorities,Energy sector development scenarios,Integrated assessment models,Multi-criteria decision making,Optimization,Sustainability},
number = {2017},
pages = {862--871},
title = {{Multi-criteria ranking of energy generation scenarios with Monte Carlo simulation}},
volume = {185},
year = {2017}
}
@article{Gulpinar2004,
abstract = {In this paper, three approaches are presented for generating scenario trees for financial portfolio problems. These are based on simulation, optimization and hybrid simulation/optimization. In the simulation approach, the price scenarios at each time period are generated as the centroids of random scenario simulations generated sequentially or in parallel. The optimization method generates a number of discrete outcomes which satisfy specified statistical properties by solving either a sequence of non-linear optimization models (one at each node of the scenario tree) or one large optimization problem. In the hybrid approach, the optimization problem is reduced in size by fixing price variables to values obtained by simulation. These procedures are backtested using historical data and computational results are presented. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {G{\"{u}}lpinar, Nalan and Rustem, Ber{\c{c}} and Settergren, Reuben},
doi = {10.1016/S0165-1889(03)00113-1},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/G{\"{u}}lpinar, Rustem, Settergren - 2004 - Simulation and optimization approaches to scenario tree generation.pdf:pdf},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {Computational finance,Non-linear optimization,Scenario generation,Simulation,Stochastic programming},
number = {7},
pages = {1291--1315},
title = {{Simulation and optimization approaches to scenario tree generation}},
volume = {28},
year = {2004}
}
@phdthesis{Christian2017,
author = {Christian, Brianna},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Christian - 2017 - Solution Approaches to Large Scale Multistage Stochastic Programs with Endogenous Endogenous and Exogenous Uncertaint.pdf:pdf},
keywords = {clinical trial planning,multistage stochastic programming,new technology investment planning,optimization under uncertainty},
pages = {210},
title = {{Solution Approaches to Large Scale Multistage Stochastic Programs with Endogenous Endogenous and Exogenous Uncertainty}},
year = {2017}
}
@article{Liu2002,
abstract = {The even-flow harvest scheduling problem arises when the forestry agency has evolved into a rigid non-declining even-flow policy. In this paper, we investigate model formulation and solution strategies for the even-flow harvest scheduling problem. A multiple-objective linear programming problem is formulated for even-flow harvest scheduling problems with multiple-site classes and multiple periods. The aim of this problem is to simultaneously maximize a desired harvest-volume per hectare for each period of planning horizon and the total economic return. A block diagonal constraint structure, with many sets of network sub-problems and a set of coupling constraints, is identified in this linear programming problem. A longest path method for each of network sub-problems and a primal-dual steepest-edge algorithm for the entire problem are developed. The developed algorithm has been coded in Borland C++ and implemented on a personal computer. An illustrative example is used to display the detailed procedure for the developed algorithm and a real-world case study is used to show the trade-off between desired even-flow harvest volume policy and total economic return. Results show the potential benefits of this approach. International Federation of Operational Research Societies 2002.},
author = {Liu, Chiun Ming},
doi = {10.1111/1475-3995.00339},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Liu - 2002 - A Primal-dual Steepest-edge Method for Even-flow Harvest Scheduling Problems.pdf:pdf},
issn = {14753995},
journal = {International Transactions in Operational Research},
keywords = {Even-flow policy,Harvest scheduling,Primal-dual steepest-edge method},
number = {1},
pages = {33--50},
title = {{A Primal-dual Steepest-edge Method for Even-flow Harvest Scheduling Problems}},
volume = {9},
year = {2002}
}
@article{Egging2013,
abstract = {This paper presents and implements a Benders Decomposition type of algorithm for large-scale, stochastic multi-period mixed complementarity problems. The algorithm is applied to various multi-stage natural gas market models accounting for market power exertion by traders. Due to the non-optimization nature of the natural gas market problem, a straightforward implementation of the traditional Benders Decomposition is not possible. The master and subproblems can be derived from the underlying optimization problems and transformed into complementarity problems. However, to complete the master problems optimality cuts are added using the variational inequality-based method developed in Gabriel and Fuller (2010). In this manner, an alternative derivation of Benders Decomposition for Stochastic MCP is presented, thereby making this approach more applicable to a broader audience. The algorithm can successfully solve problems with up to 256 scenarios and more than 600 thousand variables, and problems with over 117 thousand variables with more than two thousand first-stage capacity expansion variables. The algorithm is efficient for solving two-stage problems. The computational time reduction for other stochastic problems is considerable and would be even larger if a parallel implementation of the algorithm were used. The paper concludes with a discussion of infrastructure expansion results, illustrating the impact of hedging on investment timing and optimal capacity sizes. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
annote = {algorithm efficient for two stage and considerable improvement for other stochastic programs},
author = {Egging, Ruud},
doi = {10.1016/j.ejor.2012.11.024},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Egging - 2013 - Benders Decomposition for multi-stage stochastic mixed complementarity problems-Applied to a global natural gas market m.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Benders Decomposition,Natural gas market models,OR in energy,Optimality cut,Stochastic mixed complementarity problem,Stochastic programming},
number = {2},
pages = {341--353},
publisher = {Elsevier B.V.},
title = {{Benders Decomposition for multi-stage stochastic mixed complementarity problems-Applied to a global natural gas market model}},
url = {http://dx.doi.org/10.1016/j.ejor.2012.11.024},
volume = {226},
year = {2013}
}
@article{Ryan2016,
abstract = {Scenario decomposition algorithms for stochastic programs compute bounds by dualizing all nonanticipativity constraints and solving individual scenario problems independently. We develop an approach that improves upon these bounds by re-enforcing a carefully chosen sub-set of nonanticipativity constraints, effectively placing scenarios into 'groups'. Specifically, we formulate an optimization problem for grouping scenarios that aims to improve the bound by optimizing a proxy metric based on information obtained from evaluating a subset of candi-date feasible solutions. We show that the proposed grouping problem is NP-hard in general, identify a polynomially solvable case, and present a mixed integer programming formulation. We use the proposed grouping scheme as a preprocessing step for a particular scenario de-composition algorithm and demonstrate its effectiveness for solving standard test instances of two-stage 0-1 stochastic programs. Using this approach, we are able to prove optimality for all previously unsolved instances of a standard test set. Finally, the idea is extended to propose a finitely convergent algorithm for two-stage stochastic programs with a finite feasible region.},
author = {Ryan, Kevin and Ahmed, Shabbir and Dey, Santanu S and Rajan, Deepak},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Ryan et al. - 2016 - Optimization Driven Scenario Grouping.pdf:pdf},
pages = {1--15},
title = {{Optimization Driven Scenario Grouping}},
year = {2016}
}
@article{Kaut2014,
abstract = {Infrastructure-planning models are challenging because of their combination of different time scales: while planning and building the infrastructure involves strategic decisions with time horizons of many years, one needs an operational time scale to get a proper picture of the infrastructure's performance and profitability. In addition, both the strategic and operational levels are typically subject to significant uncertainty, which has to be taken into account. This combination of uncertainties on two different time scales creates problems for the traditional multistage stochastic-programming formulation of the problem due to the exponential growth in model size. In this paper, we present an alternative formulation of the problem that combines the two time scales, using what we call a multi-horizon approach, and illustrate it on a stylized optimization model. We show that the new approach drastically reduces the model size compared to the traditional formulation and present two real-life applications from energy planning. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
author = {Kaut, Michal and Midthun, Kjetil T. and Werner, Adrian S. and Tomasgard, Asgeir and Hellemo, Lars and Fodstad, Marte},
doi = {10.1007/s10287-013-0182-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Kaut et al. - 2014 - Multi-horizon stochastic programming.pdf:pdf},
isbn = {1619-697X},
issn = {1619697X},
journal = {Computational Management Science},
keywords = {Energy planning,Multistage,Scenario tree construction,Stochastic programming},
number = {1-2},
pages = {179--193},
title = {{Multi-horizon stochastic programming}},
volume = {11},
year = {2014}
}
@article{Xie2018,
author = {Xie, Fei and Huang, Yongxi},
doi = {10.1016/j.tre.2018.01.015},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Xie, Huang - 2018 - A multistage stochastic programming model for a multi-period strategic expansion of biofuel supply chain under evolv.pdf:pdf},
issn = {13665545},
journal = {Transportation Research Part E: Logistics and Transportation Review},
keywords = {Biofuel supply chain,Enhanced nested decomposition,Multistage stochastic programming,Uncertainty,biofuel supply chain,multistage stochastic programming},
month = {mar},
number = {January},
pages = {130--148},
publisher = {Elsevier},
title = {{A multistage stochastic programming model for a multi-period strategic expansion of biofuel supply chain under evolving uncertainties}},
url = {https://doi.org/10.1016/j.tre.2018.01.015 https://linkinghub.elsevier.com/retrieve/pii/S1366554517306531},
volume = {111},
year = {2018}
}
@article{Pagnoncelli2017,
abstract = {{\textcopyright} 2015, Springer Science+Business Media New York. We study the exploitation of a one species, multiple stand forest plantation when timber price is governed by a stochastic process. Our model is a stochastic dynamic program with a weighted mean-risk objective function, and our main risk measure is the Conditional Value-at-Risk. We consider two stochastic processes, geometric Brownian motion and Ornstein–Uhlenbeck: in the first case, we completely characterize the optimal policy for all possible choices of the parameters while in the second, we provide sufficient conditions assuring that harvesting everything available is optimal. In both cases we solve the problem theoretically for every initial condition. We compare our results with the risk neutral framework and generalize our findings to any coherent risk measure that is affine on the current price.},
author = {Pagnoncelli, Bernardo K. and Piazza, Adriana},
doi = {10.1007/s10479-015-1963-9},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pagnoncelli, Piazza - 2017 - The optimal harvesting problem under price uncertainty the risk averse case.pdf:pdf},
issn = {15729338},
journal = {Annals of Operations Research},
keywords = {Coherent risk measures,Forestry,Multistage stochastic programming,Optimal harvesting},
number = {2},
pages = {479--502},
publisher = {Springer US},
title = {{The optimal harvesting problem under price uncertainty: the risk averse case}},
volume = {258},
year = {2017}
}
@article{Pantuso2019,
author = {Pantuso, Giovanni and Boomsma, Trine K.},
doi = {10.1007/s10479-019-03181-7},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pantuso, Boomsma - 2019 - On the number of stages in multistage stochastic programs.pdf:pdf},
issn = {0254-5330},
journal = {Annals of Operations Research},
keywords = {Bounds,Multistage stochastic programming,Optimization under uncertainty,Value of the stochastic solution,bounds,multistage stochastic programming,optimization under uncertainty,solution,value of the stochastic},
month = {feb},
number = {1985},
pages = {1--8},
publisher = {Springer US},
title = {{On the number of stages in multistage stochastic programs}},
url = {http://link.springer.com/10.1007/s10479-019-03181-7},
volume = {1},
year = {2019}
}
@article{Pukkala1998,
author = {Pukkala, Timo},
doi = {10.1016/S0378-1127(98)00339-9},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pukkala - 1998 - Multiple risks in multi-objective forest planning integration and importance.pdf:pdf},
isbn = {3587315140},
journal = {Forest Ecology and Management},
keywords = {risk preferences,scenario technique,stochastic optimization,utility function},
pages = {265--284},
title = {{Multiple risks in multi-objective forest planning : integration and importance}},
url = {https://doi.org/10.1016/S0378-1127(98)00339-9},
volume = {111},
year = {1998}
}
@article{Latta2010,
abstract = {As global climate changes over the next century, forest productivity is expected to change as well. Using PRISM climate and productivity data measured on a grid of 3356 plots, we developed a simultaneous autoregressive (SAR) model to estimate the impacts of climate change on potential productivity of Pacific Northwest (PNW) forests of the United States. Productivity, measured by projected potential mean annual increment (PMAI) at culmination, is explained by the interaction of annual temperature, precipitation, and precipitation in excess of evapotranspiration through the growing season. By utilizing information regarding spatial error in the SAR model, the resulting spatial bias is reduced thereby improving the accuracy of the resulting maps. The model, coupled with climate change output from four generalized circulation models, was used to predict the productivity impacts of four different scenarios derived from the fourth IPCC special report on emissions, representing different future economic and environmental states of the world, viz., scenario A1B, A2, B1 (low growth, high economic development and low energy usage), and COMMIT. In these scenarios, regional average temperature is expected to increase from 0.5 to 4.5 °C, while precipitation shows no clear trend over time. For the west and east side of the Cascade Mountains, respectively, PMAI increases: 7{\%} and 20{\%} under A1B scenario; 8{\%} and 23{\%} under scenario A2; 5{\%} and 15{\%} under scenario B1, and 2{\%} and 5{\%} under the COMMIT scenario. These projections should be viewed as potential changes in productivity, since they do not reflect the mitigating effects of any shifts in management or public policy. For managers and policy makers, the results suggest the relative magnitude of effects and the potential variability of impacts across a range of climate scenarios. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Latta, Gregory and Temesgen, Hailemariam and Adams, Darius and Barrett, Tara},
doi = {10.1016/j.foreco.2009.09.003},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Latta et al. - 2010 - Analysis of potential impacts of climate change on forests of the United States Pacific Northwest.pdf:pdf},
issn = {03781127},
journal = {Forest Ecology and Management},
keywords = {Mapping climate change,Mean annual increment,Simultaneous autoregressive model,Site class},
number = {4},
pages = {720--729},
title = {{Analysis of potential impacts of climate change on forests of the United States Pacific Northwest}},
volume = {259},
year = {2010}
}
@article{Rockafellar1991,
author = {Rockafellar, R and Wets, Roger J.-B.},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Rockafellar, Wets - 1991 - Scenarios and policy aggregation in optimization under uncertainty.pdf:pdf},
journal = {Mathematics of Operations Research},
keywords = {augmented lagrangians,authors was supported in,decomposition,infor-,mation prices,methods,multistage decision problems,optimization under uncertainty,part by grants from,progressive hedging,proximal point algorithm,scenario analysis,splitting methods,stochastic programming,the air force office,the work of both},
number = {1},
pages = {119--147},
title = {{Scenarios and policy aggregation in optimization under uncertainty}},
url = {https://pdfs.semanticscholar.org/4ab8/028748c89b226fd46cf9f45de88218779572.pdf},
volume = {16},
year = {1991}
}
@article{Høyland2003,
author = {H{\o}yland, Kjetil and Kaut, Michal and Wallace, Stein W},
doi = {10.1023/A:1021853807313},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/H{\o}yland, Kaut, Wallace - 2003 - A Heuristic for Moment-Matching.pdf:pdf},
journal = {Computational Optimization and Applications},
keywords = {cholesky decomposition,heuristics,scenario tree generation,stochastic programming},
pages = {169--185},
title = {{A Heuristic for Moment-Matching}},
volume = {24},
year = {2003}
}
@article{Hochreiter2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1404.5711v1},
author = {Hochreiter, Ronald},
doi = {10.1007/978-3-319-20430-7_27},
eprint = {arXiv:1404.5711v1},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Hochreiter - 2016 - Modeling multi-stage decision optimization problems.pdf:pdf},
issn = {00758442},
journal = {Lecture Notes in Economics and Mathematical Systems},
number = {April},
pages = {209--214},
title = {{Modeling multi-stage decision optimization problems}},
volume = {682},
year = {2016}
}
@article{Fleishman1978,
author = {Fleishman, Allen I.},
doi = {10.1007/BF02293811},
issn = {0033-3123},
journal = {Psychometrika},
month = {dec},
number = {4},
pages = {521--532},
title = {{A method for simulating non-normal distributions}},
url = {http://link.springer.com/10.1007/BF02293811},
volume = {43},
year = {1978}
}
@article{Birge1982,
abstract = {Stochastic linear programs have been rarely used in practical situations largely because of their complexity. In evaluating these problems without finding the exact solution, a common method has been to find bounds on the expected value of perfect information. In this paper, we consider a different method. We present bounds on the value of the stochastic solution, that is, the potential benefit from solving the stochastic program over solving a deterministic program in which expected values have replaced random parameters. These bounds are calculated by solving smaller programs related to the stochastic recourse problem. {\textcopyright} 1982 The Mathematical Programming Society, Inc.},
author = {Birge, John R.},
doi = {10.1007/BF01585113},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Birge - 1982 - The value of the stochastic solution in stochastic linear programs with fixed recourse.pdf:pdf},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Expected Value of Perfect Information,Linear Programming,Stochastic Programming},
number = {1},
pages = {314--325},
title = {{The value of the stochastic solution in stochastic linear programs with fixed recourse}},
volume = {24},
year = {1982}
}
@incollection{Alfieri2005,
abstract = {Stochastic programming models have been proposed for capacity planning problems in different environments, including energy, telecommunication networks, distribution networks, and manufacturing systems. In this chapter we give an introductory tutorial to stochastic linear programming models, with emphasis on modeling techniques, rather than specialized solution methods. We consider two-stage and multi-stage stochastic programming models with recourse for manufacturing related applications, such as production planning and capacity planning with uncertainty on demand. We stress the importance of proper model formulation from two points of view: the first one is building strong mixed-integer formulations; the second one is generating scenario trees in order to suitably represent uncertainty while keeping them to a manageable size. We also compare the stochastic programming approach to traditional dynamic programming and to robust optimization.},
author = {Alfieri, A. and Brandimarte, P.},
booktitle = {Design of Advanced Manufacturing Systems: Models for Capacity Planning in Advanced Manufacturing Systems},
doi = {10.1007/1-4020-2931-4_3},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Alfieri, Brandimarte - 2005 - Stochastic programming models for manufacturing applications A tutorial introduction.pdf:pdf},
isbn = {1402029306},
keywords = {capacity planning,production planning,stochastic programming},
pages = {73--124},
title = {{Stochastic programming models for manufacturing applications: A tutorial introduction}},
year = {2005}
}
@article{Dahl2018,
abstract = {Fusarium Head Blight (FHB) is an important problem to the agricultural production and marketing system, and has led to major economic losses for wheat and barley producers in the United States, Canada and many other countries. Deoxynivalenol (DON) is a mycotoxin associated with FHB. Grain products and feed grain contaminated with DON (commonly known as vomitoxin) are subject to FDA advisory limits and as a result end-users place restrictions on this factor. This has led to steep price discounts, as well as higher risks for producers and grain merchandisers. Research has led to development of varieties that are resistant to moderately resistant to FHB. Also, studies indicate combinations of genetic resistance, fungicides and some management practices (combine settings, tillage practices, etc.) can be used to decrease losses due to FHB. This increases cost to the industry and imputes a value related to reduced FHB. The purpose of this paper is to analyze risk and determine risk premiums necessary to induce growers to adopt risk reducing technologies in the case of wheat and barley grown in the United States.},
author = {Dahl, Bruce and Wilson, William W.},
doi = {10.1016/j.agsy.2018.01.025},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Dahl, Wilson - 2018 - Risk premiums due to Fusarium Head Blight (FHB) in wheat and barley.pdf:pdf},
issn = {0308521X},
journal = {Agricultural Systems},
keywords = {DON,Fusarium Head Blight,Risk premiums,Wheat and malting barley},
number = {January},
pages = {145--153},
publisher = {Elsevier},
title = {{Risk premiums due to Fusarium Head Blight (FHB) in wheat and barley}},
url = {https://doi.org/10.1016/j.agsy.2018.01.025},
volume = {162},
year = {2018}
}
@article{Sahinidis2004,
abstract = {A large number of problems in production planning and scheduling, location, transportation, finance, and engineering design require that decisions be made in the presence of uncertainty. Uncertainty, for instance, governs the prices of fuels, the availability of electricity, and the demand for chemicals. A key difficulty in optimization under uncertainty is in dealing with an uncertainty space that is huge and frequently leads to very large-scale optimization models. Decision-making under uncertainty is often further complicated by the presence of integer decision variables to model logical and other discrete decisions in a multi-period or multi-stage setting. This paper reviews theory and methodology that have been developed to cope with the complexity of optimization problems under uncertainty. We discuss and contrast the classical recourse-based stochastic programming, robust stochastic programming, probabilistic (chance-constraint) programming, fuzzy programming, and stochastic dynamic programming. The advantages and shortcomings of these models are reviewed and illustrated through examples. Applications and the state-of-the-art in computations are also reviewed. Finally, we discuss several main areas for future development in this field. These include development of polynomial-time approximation schemes for multi-stage stochastic programs and the application of global optimization algorithms to two-stage and chance-constraint formulations. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Sahinidis, Nikolaos V.},
doi = {10.1016/j.compchemeng.2003.09.017},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Sahinidis - 2004 - Optimization under uncertainty State-of-the-art and opportunities.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Approximation algorithms,Fuzzy programming,Global optimization,Stochastic dynamic programming,Stochastic programming},
number = {6-7},
pages = {971--983},
title = {{Optimization under uncertainty: State-of-the-art and opportunities}},
volume = {28},
year = {2004}
}
@article{Ponomareva2015,
abstract = {We present an algorithm for moment-matching scenario generation. This method produces scenarios and corresponding probability weights that match exactly the given mean, the covariance matrix, the average of the marginal skewness and the average of the marginal kurtosis of each individual component of a random vector. Optimisation is not employed in the scenario generation process and thus the method is computationally more advantageous than previous approaches. The algorithm is used for generating scenarios in a mean-CVaR portfolio optimisation model. For the chosen optimisation example, it is shown that desirable properties for a scenario generator are satisfied, including in-sample and out-of-sample stability. It is also shown that optimal solutions vary only marginally with increasing number of scenarios in this example; thus, good solutions can apparently be obtained with a relatively small number of scenarios. The proposed method can be used either on its own as a computationally inexpensive scenario generator or as a starting point for non-convex optimisation based scenario generators which aim to match all the third and the fourth order marginal moments (rather than average marginal moments).},
author = {Ponomareva, K. and Roman, D. and Date, P.},
doi = {10.1016/j.ejor.2014.07.049},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Ponomareva, Roman, Date - 2015 - An algorithm for moment-matching scenario generation with application to financial portfolio optimisati.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Finance,OR in banking,Scenarios,Stochastic programming},
number = {3},
pages = {678--687},
publisher = {Elsevier B.V.},
title = {{An algorithm for moment-matching scenario generation with application to financial portfolio optimisation}},
url = {http://dx.doi.org/10.1016/j.ejor.2014.07.049},
volume = {240},
year = {2015}
}
@article{Manerba2019,
abstract = {We study a multi-product multi-supplier procurement problem in the Automotive sector involving both supplier selection and ordering quantity decisions, and further complicated by the presence of total quantity discounts, business activation costs, and demand uncertainty. Recent works have shown the importance of explicitly incorporate demand uncertainty in this economic setting, along with the evidence about the computational burden of solving the relative Stochastic Programming models for a sufficiently large number of scenarios. In this work, we propose different solution strategies to efficiently cope with these models by taking advantage of the particular structure of the stochastic problem. More precisely, we propose and test several variants of a Progressive Hedging based heuristic approach as well as a Benders algorithm. The results obtained on benchmark instances show how the proposed methods outperform the existing ones and the state-of-the-art solvers in terms of efficiency and solution quality. In particular, thanks to the developed Progressive Hedging, we have been able to solve for the first time problem instances with up to 20 suppliers and 30 products.},
author = {Manerba, Daniele and Perboli, Guido},
doi = {10.1016/j.cor.2018.08.010},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Manerba, Perboli - 2019 - New solution approaches for the capacitated supplier selection problem with total quantity discount and activa.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Progressive Hedging,Stochastic demand,Supplier selection,Total Quantity Discount},
pages = {29--42},
publisher = {Elsevier Ltd},
title = {{New solution approaches for the capacitated supplier selection problem with total quantity discount and activation costs under demand uncertainty}},
url = {https://doi.org/10.1016/j.cor.2018.08.010},
volume = {101},
year = {2019}
}
@article{Dixon1980,
author = {Dixon, Bruce L. and Howitt, Richard E.},
doi = {10.2307/1240204},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Dixon, Howitt - 1980 - Resource Production Under Uncertainty A Stochastic Control Approach to Timber Harvest Scheduling.pdf:pdf},
issn = {0002-9092},
journal = {American Journal of Agricultural Economics},
month = {aug},
number = {3},
pages = {499--507},
title = {{Resource Production Under Uncertainty: A Stochastic Control Approach to Timber Harvest Scheduling}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.2307/1240204},
volume = {62},
year = {1980}
}
@article{DiDomenica2007,
abstract = {Stochastic programming brings together models of optimum resource allocation and models of randomness to create a robust decision-making framework. The models of randomness with their finite, discrete realisations are called scenario generators. In this paper, we investigate the role of such a tool within the context of a combined information and decision support system. We explain how two well-developed modelling paradigms, decision models and simulation models can be combined to create "business analytics" which is based on ex-ante decision and ex-post evaluation. We also examine how these models can be integrated with data marts of analytic organisational data and decision data. Recent developments in on-line analytical processing (OLAP) tools and multidimensional data viewing are taken into consideration. We finally introduce illustrative examples of optimisation, simulation models and results analysis to explain our multifaceted view of modelling. In this paper, our main objective is to explain to the information systems (IS) community how advanced models and their software realisations can be integrated with advanced IS and DSS tools. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0903.1150},
author = {{Di Domenica}, Nico and Mitra, Gautam and Valente, Patrick and Birbilis, George},
doi = {10.1016/j.dss.2006.06.013},
eprint = {0903.1150},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Di Domenica et al. - 2007 - Stochastic programming and scenario generation within a simulation framework An information systems perspect.pdf:pdf},
isbn = {0167-9236},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Business analytics,DSS,OLAP,Scenario generation,Simulation,Stochastic programming},
number = {4},
pages = {2197--2218},
pmid = {18382848},
title = {{Stochastic programming and scenario generation within a simulation framework: An information systems perspective}},
volume = {42},
year = {2007}
}
@article{Xu2015,
author = {Xu, Bin and Zhong, Ping-An and Zambon, Renato C. and Zhao, Yunfa and Yeh, William W.-G.},
doi = {10.1002/2014WR016828},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Xu et al. - 2015 - Scenario tree reduction in stochastic programming with recourse for hydropower operations.pdf:pdf},
issn = {00431397},
journal = {Water Resources Research},
month = {aug},
number = {8},
pages = {6359--6380},
title = {{Scenario tree reduction in stochastic programming with recourse for hydropower operations}},
url = {http://doi.wiley.com/10.1002/2014WR016828},
volume = {51},
year = {2015}
}
@article{Sen2005,
abstract = {In this chapter, we will study algorithms for both two-stage as well as multi-stage stochastic mixed-integer programs. We present stagewise (resource-directive) decomposition methods for two-stage models, and scenario (price-directive) decomposition methods for multi-stage models. The manner in which these models are decomposed relies not only on the specific data elements that are random, but also on the manner in which the integer (decision) variables interact with these data elements. Accordingly, we study a variety of structures ranging from models that allow randomness in all data elements, to those that allow only specific elements (e.g. right-hand-side) to be influenced by randomness. Since the decomposition algorithms presented here are based on certain results from integer programming, the relevant background is also provided in this chapter. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Sen, Suvrajeet},
doi = {10.1016/S0927-0507(05)12009-X},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Sen - 2005 - Algorithms for Stochastic Mixed-Integer Programming Models.pdf:pdf},
issn = {09270507},
journal = {Handbooks in Operations Research and Management Science},
number = {C},
pages = {515--558},
title = {{Algorithms for Stochastic Mixed-Integer Programming Models}},
volume = {12},
year = {2005}
}
@article{Rachel2015,
author = {{St. John}, Rachel and T{\'{o}}th, S{\'{a}}ndor F.},
doi = {10.1007/s10479-012-1301-4},
issn = {0254-5330},
journal = {Annals of Operations Research},
month = {jan},
pages = {235--257},
title = {{Spatially explicit forest harvest scheduling with difference equations}},
url = {http://link.springer.com/10.1007/s10479-012-1301-4},
volume = {232},
year = {2015}
}
@article{Miehle2009,
abstract = {In forest management and ecological research, consideration of the impacts and risks of climate change or management optimisation is complex. Computer models have long been applied as tools for these tasks. Process-based forest growth models claim to overcome the limitations of empirical statistical models, but the capacity of different process-based models and modelling approaches have rarely been compared directly. This study evaluates stepwise multiple regression models in comparison to four process-based modelling approaches (3-PG, 3-PG+, CABALA and Forest-DNDC) for greenfield predictions of Eucalyptus globulus plantation growth from 2 to 8 years after planting throughout southern Australia. The stepwise multiple regression models could not simulate plantation growth to a satisfactory level of precision over the entire simulation period, although 2 years after planting model efficiency was 0.46, greater than for any of the process-based models. The variables that were statistically important to predict early plantation growth were mean minimum temperature, stocking rate and the amount of applied N fertiliser. For plantations between 4 and 8 years of age, coefficients of model efficiency were between -0.55 and -0.99. Only process-based models provided the flexibility to realistically predict the impacts of the different growth conditions throughout of the simulation period. Amongst the process-based models, Forest-DNDC achieved the greatest model efficiency (0.28) at 2 years after planting and was the most consistent performing model (0.20-0.30), whereas CABALA achieved the greates model efficiency (0.70) after 8 years of plantation growth. Both 3-PG models performed best for 6-year-old plantations, but throughout the simulation period their predictive precision was strongly dependent on estimating site fertility. For 3-PG+, a statistical approach to estimate site fertility resulted in a model efficiency of 0.28 at 6 years after planting, whereas a subjective estimation of site fertility for 3-PG resulted in a model efficiency of 0.58. In general, the process-based models had difficulties in simulating very young plantations at less then 4 years after planting, plantations with high tree mortality rates and plantation response to extreme silvicultural management operations. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Miehle, Peter and Battaglia, Michael and Sands, Peter J. and Forrester, David I. and Feikema, Paul M. and Livesley, Stephen J. and Morris, Jim D. and Arndt, Stefan K.},
doi = {10.1016/j.ecolmodel.2008.12.010},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Miehle et al/Ecological Modelling/Miehle et al. - 2009 - A comparison of four process-based models and a statistical regression model to predict growth of Eucalyptus glob.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {3-PG,CABALA,Eucalyptus globulus,Forest growth model,Forest-DNDC,Model comparison},
number = {5},
pages = {734--746},
title = {{A comparison of four process-based models and a statistical regression model to predict growth of Eucalyptus globulus plantations}},
volume = {220},
year = {2009}
}
@article{Crespi2018,
abstract = {The question we address is how robust solutions react to changes in the uncertainty set. We prove the location of robust solutions with respect to the magnitude of a possible decrease in uncertainty, namely when the uncertainty set shrinks, and convergence of the sequence of robust solutions. In decision making, uncertainty may arise from incomplete information about people's (stakeholders, voters, opinion leaders, etc.) perception about a specific issue. Whether the decision maker (DM) has to look for the approval of a board or pass an act, they might need to define the strategy that displeases the minority. In such a problem, the feasible region is likely to unchanged, while uncertainty affects the objective function. Hence the paper studies only this framework.},
author = {Crespi, Giovanni P. and Kuroiwa, Daishi and Rocca, Matteo},
doi = {10.1016/j.orp.2018.03.001},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Crespi, Kuroiwa, Rocca/Operations Research Perspectives/Crespi, Kuroiwa, Rocca - 2018 - Robust optimization Sensitivity to uncertainty in scalar and vector cases, with applications.pdf:pdf},
issn = {22147160},
journal = {Operations Research Perspectives},
keywords = {Decision analysis,Multiple objective programming,Set optimization,Uncertainty modelling},
pages = {113--119},
publisher = {Elsevier Ltd},
title = {{Robust optimization: Sensitivity to uncertainty in scalar and vector cases, with applications}},
url = {https://doi.org/10.1016/j.orp.2018.03.001},
volume = {5},
year = {2018}
}
@article{Kooten1992,
author = {Kooten, Gerrit Cornelis Van},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Kooten - 1992 - Modeling the effect of uncertainty on timber harvest A suggested approach and empirical example.pdf:pdf},
journal = {Journal of Agricultural and Resource Economics},
keywords = {been studied by a,dynamic programming,fire,forest management under uncertainty,has,he finds that the,number of researchers,of catastrophic mortality,particularly in the case,reed,rotation age can increase,silviculture,tendency is for uncertainty,the optimal,to reduce rotation,under uncertainty,viz,while routledge demonstrates that,williams},
number = {May},
title = {{Modeling the effect of uncertainty on timber harvest: A suggested approach and empirical example}},
year = {1992}
}
@article{Saupe2019,
author = {Saupe, Erin E and Myers, Corinne E and {Townsend Peterson}, A. and Sober{\'{o}}n, Jorge and Singarayer, Joy and Valdes, Paul and Qiao, Huijie},
doi = {10.1038/s41559-019-0962-7},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Saupe et al. - 2019 - Spatio-temporal climate change contributes to latitudinal diversity gradients.pdf:pdf},
isbn = {4155901909627},
issn = {2397-334X},
journal = {Nature Ecology {\&} Evolution},
month = {sep},
title = {{Spatio-temporal climate change contributes to latitudinal diversity gradients}},
url = {http://www.nature.com/articles/s41559-019-0962-7},
year = {2019}
}
@article{Escudero2007,
abstract = {We generalize the definition of the bounds for the optimal value of the objective function for various deterministic equivalent models in multistage stochastic programs. The parameters EVPI and VSS were introduced for two-stage models. The parameter EVPI, the expected value of perfect information, measures how much it is reasonable to pay to obtain perfect information about the future. The parameter VSS, the value of the stochastic solution, allows us to obtain the goodness of the expected solution value when the expected values are replaced by the random values for the input variables. We extend the definition of these parameters to the multistage stochastic model and prove a similar chain of inequalities with the lower and upper bounds depending substantially on the structure of the problem.},
author = {Escudero, Laureano F. and Gar{\'{i}}n, Araceli and Merino, Mar{\'{i}}a and P{\'{e}}rez, Gloria},
doi = {10.1007/s11750-007-0005-4},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Escudero et al. - 2007 - The value of the stochastic solution in multistage problems.pdf:pdf},
issn = {1134-5764},
journal = {Top},
number = {1},
pages = {48--64},
title = {{The value of the stochastic solution in multistage problems}},
volume = {15},
year = {2007}
}
@article{Fattahi2018,
abstract = {In this paper, we address a multi-period supply chain network redesign problem in which customer zones have price-dependent stochastic demand for multiple products. A novel multi-stage stochastic program is proposed to simultaneously make tactical decisions including products' prices and strategic redesign decisions. Existing uncertainty in potential demands of customer zones is modeled through a finite set of scenarios, described in the form of a scenario tree. The scenarios are generated using a Latin Hypercube Sampling method and then a forward scenario construction technique is employed to create a suitable scenario tree. The multi-stage stochastic problem is formulated as a mixed-integer linear programming model and then Benders decomposition algorithm is applied for solving it. Numerical results demonstrate the significance of the stochastic model as well as the good performance of Benders algorithm. The scenario tree construction method is also evaluated in terms of out-of-sample and in-sample stability. Finally, several key managerial and practical insights in terms of pricing issues are highlighted.},
author = {Fattahi, Mohammad and Govindan, Kannan and Keyvanshokooh, Esmaeil},
doi = {10.1016/j.cor.2017.12.016},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Fattahi, Govindan, Keyvanshokooh - 2018 - A multi-stage stochastic program for supply chain network redesign problem with price-dependen.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Benders decomposition,Multi-stage stochastic programming,Non-anticipativity constraints,Pricing and revenue management,Scenario reduction,Supply chain network redesign},
pages = {314--332},
publisher = {Elsevier Ltd},
title = {{A multi-stage stochastic program for supply chain network redesign problem with price-dependent uncertain demands}},
url = {https://doi.org/10.1016/j.cor.2017.12.016},
volume = {100},
year = {2018}
}
@article{Papavasiliou2018,
author = {Papavasiliou, Anthony and Mou, Yuting and Cambier, Leopold and Scieur, Damien},
doi = {10.1109/TSTE.2017.2748463},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Papavasiliou et al. - 2018 - Application of Stochastic Dual Dynamic Programming to the Real-Time Dispatch of Storage Under Renewable Sup.pdf:pdf},
issn = {1949-3029},
journal = {IEEE Transactions on Sustainable Energy},
month = {apr},
number = {2},
pages = {547--558},
title = {{Application of Stochastic Dual Dynamic Programming to the Real-Time Dispatch of Storage Under Renewable Supply Uncertainty}},
url = {http://ieeexplore.ieee.org/document/8024054/},
volume = {9},
year = {2018}
}
@article{Moss2010,
author = {Moss, Richard H. and Edmonds, Jae A. and Hibbard, Kathy A. and Manning, Martin R. and Rose, Steven K. and van Vuuren, Detlef P. and Carter, Timothy R. and Emori, Seita and Kainuma, Mikiko and Kram, Tom and Meehl, Gerald A. and Mitchell, John F. B. and Nakicenovic, Nebojsa and Riahi, Keywan and Smith, Steven J. and Stouffer, Ronald J. and Thomson, Allison M. and Weyant, John P. and Wilbanks, Thomas J.},
doi = {10.1038/nature08823},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7282},
pages = {747--756},
title = {{The next generation of scenarios for climate change research and assessment}},
url = {http://www.nature.com/articles/nature08823},
volume = {463},
year = {2010}
}
@article{Higle2010,
abstract = {Over the past decade, several stochastic approaches have been proposed for two-stage stochastic programs. Many of these algorithms have attractive computational as well as conceptual properties (e.g. convergence with probability one). This paper expands the realm of such approaches to multistage convex stochastic programming problems. We present a stochastic scenario decomposition (SSD) algorithm which is a statistically motivated cutting plane algorithm for the solution of multistage stochastic programs. The method is based on solving a dual problem in which the variables correspond to multipliers associated with the non-anticipativity constraints of the primal problem. Our analytical results verify conditions under which SSD identifies an optimal solution asymptotically. We also overcome some computational hurdles resulting from increases in the column dimension of the SSD master problem. We propose a variable aggregation scheme that allows us to solve much smaller master programs without sacrificing solution quality. Our computational results demonstrate the effectiveness of this aggregation scheme in solving the SSD master program.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Higle, Julia L. and Rayco, Brenda and Sen, Suvrajeet},
doi = {10.1093/imaman/dpp001},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Higle, Rayco, Sen - 2010 - Stochastic scenario decomposition for multistage stochastic programs.pdf:pdf},
isbn = {9788578110796},
issn = {14716798},
journal = {IMA Journal of Management Mathematics},
keywords = {Decomposition,Duality,Stochastic programming},
number = {1},
pages = {39--66},
pmid = {25246403},
title = {{Stochastic scenario decomposition for multistage stochastic programs}},
volume = {21},
year = {2010}
}
@article{Wang2008,
abstract = {We propose a sample average approximation (SAA) method for stochastic programming problems with expected value constraints. Such problems arise, for example, in portfolio selection with constraints on conditional value-at-risk (CVaR). We provide a convergence analysis and a statistical validation scheme for the proposed method. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Wang, Wei and Ahmed, Shabbir},
doi = {10.1016/j.orl.2008.05.003},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Wang, Ahmed - 2008 - Sample average approximation of expected value constrained stochastic programs.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {Conditional value-at-risk,Expected value constrained stochastic program,Portfolio optimization,Sample average approximation},
number = {5},
pages = {515--519},
title = {{Sample average approximation of expected value constrained stochastic programs}},
volume = {36},
year = {2008}
}
@article{He2019,
abstract = {How to improve resource utilization and reduce energy consumption are two challenging tasks in iron mines. The realization of resource utilization and energy conservation goals depends on proper investment strategy on key production processes with relatively high resource loss or energy consumption. However, none of literature have explored the decision-making issue of investment strategy combined with the mining and dressing grades from the perspective of system engineering. Focusing on the entire mine system, this study links the investment decision-making of resource utilization and energy conservation with the determination of the grades combination, and obtains the investment strategies to maximize the goals of resource utilization and energy conservation. A nonlinear multi-objective constrained optimization model is established, and then Monte Carlo simulation and intelligent computation methods are fused to be MC-IO algorithm, to find out the optimal investment strategy and grades combination. Taking DA iron mine in China as an empirical study, five different investment strategies with grades combination are obtained. The results indicate the feasibility and validity of the proposed methodology. This study has provided a scientific and feasible approach for improving resource utilization and energy conservation in iron mines.},
author = {He, Yong and Liao, Nuo and Rao, Jiwen and Fu, Feifei and Chen, Zhihao},
doi = {10.1016/j.jclepro.2019.05.347},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/He et al. - 2019 - The optimization of investment strategy for resource utilization and energy conservation in iron mines based on Monte.pdf:pdf},
issn = {09596526},
journal = {Journal of Cleaner Production},
keywords = {Energy conservation,Intelligent computation,Investment strategy optimization,Monte Carlo stimulation,Resource utilization},
pages = {672--691},
publisher = {Elsevier Ltd},
title = {{The optimization of investment strategy for resource utilization and energy conservation in iron mines based on Monte Carlo and intelligent computation}},
url = {https://doi.org/10.1016/j.jclepro.2019.05.347},
volume = {232},
year = {2019}
}
@article{Hoyland2001,
author = {H{\o}yland, Kjetil and Wallace, Stein W},
doi = {10.1287/mnsc.47.2.295.9834},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/H{\o}yland, Wallace - 2001 - Generating Scenario Trees for Multistage Decision Problems.pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
month = {feb},
number = {2},
pages = {295--307},
title = {{Generating Scenario Trees for Multistage Decision Problems}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.47.2.295.9834},
volume = {47},
year = {2001}
}
@article{Guo2019,
abstract = {We study how to model and handle correlated travel times in two-stage stochastic vehicle-routing problems. We allow these travel times to be correlated in time and space; that is, the travel time on one link in one period can be correlated to travel times on the same link in the next and previous periods as well as travel times on neighboring links (links sharing a node) in both the same and the following periods. Hence, we are handling a very high-dimensional dependent random vector. We discuss how such vehicle-routing problems should be modeled in time and space, how the random vector can be represented, and how scenarios (discretizations) can meaningfully be generated to be used in a stochastic program. We assume that the stochastic vehicle-routing problem is being solved by a search heuristic and focus on the objective function evaluation for any given solution. Numerical procedures are given and tested. As an example, our largest case has 142 nodes, 418 road links, and 60 time periods, leading to 25,080 dependent random variables. To achieve an objective function evaluation stability of 1{\%}, we need only 15 scenarios for problem instances with 64 customer nodes and nine vehicles. The online supplement is available at https://doi.org/10.1287/ijoc.2019.0906.},
author = {Guo, Zhaoxia and Wallace, Stein W. and Kaut, Michal},
doi = {10.1287/ijoc.2019.0906},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Guo, Wallace, Kaut - 2019 - Vehicle Routing with Space- and Time-Correlated Stochastic Travel Times Evaluating the Objective Function.pdf:pdf},
isbn = {0000000159},
issn = {1091-9856},
journal = {INFORMS Journal on Computing},
month = {jun},
number = {September},
pages = {1--17},
title = {{Vehicle Routing with Space- and Time-Correlated Stochastic Travel Times: Evaluating the Objective Function}},
url = {http://pubsonline.informs.org/doi/10.1287/ijoc.2019.0906},
volume = {Articles i},
year = {2019}
}
@misc{CPLEX2019,
author = {CPLEX, IBM ILOG},
keywords = {ibm2},
title = {ibm},
url = {www.ibm.com},
year = {2019}
}
@article{Lohndorf2016,
abstract = {This work presents an empirical analysis of popular scenario generation methods for stochastic optimization, including quasi-Monte Carlo, moment matching, and methods based on probability metrics, as well as a new method referred to as Voronoi cell sampling. Solution quality is assessed by measuring the error that arises from using scenarios to solve a multi-dimensional newsvendor problem, for which analytical solutions are available. In addition to the expected value, the work also studies scenario quality when minimizing the expected shortfall using the conditional value-at-risk. To quickly solve problems with millions of random parameters, a reformulation of the risk-averse newsvendor problem is proposed which can be solved via Benders decomposition. The empirical analysis identifies Voronoi cell sampling as the method that provides the lowest errors, with particularly good results for heavy-tailed distributions. A controversial finding concerns evidence for the ineffectiveness of widely used methods based on minimizing probability metrics under high-dimensional randomness.},
author = {L{\"{o}}hndorf, Nils},
doi = {10.1016/j.ejor.2016.05.021},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/L{\"{o}}hndorf - 2016 - An empirical analysis of scenario generation methods for stochastic optimization.pdf:pdf},
isbn = {1557254125},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Monte Carlo methods,Probability metrics,Sample average approximation,Scenario generation,Stochastic optimization},
number = {1},
pages = {121--132},
title = {{An empirical analysis of scenario generation methods for stochastic optimization}},
volume = {255},
year = {2016}
}
@article{Zou2019,
abstract = {Multistage stochastic integer programming (MSIP) combines the difficulty of uncertainty, dynamics, and non-convexity, and constitutes a class of extremely challenging problems. A common formulation for these problems is a dynamic programming formulation involving nested cost-to-go functions. In the linear setting, the cost-to-go functions are convex polyhedral, and decomposition algorithms, such as nested Benders' decomposition and its stochastic variant, stochastic dual dynamic programming (SDDP), which proceed by iteratively approximating these functions by cuts or linear inequalities, have been established as effective approaches. However, it is difficult to directly adapt these algorithms to MSIP due to the nonconvexity of integer programming value functions. In this paper we propose an extension to SDDP—called stochastic dual dynamic integer programming (SDDiP)—for solving MSIP problems with binary state variables. The crucial component of the algorithm is a new reformulation of the subproblems in each stage and a new class of cuts, termed Lagrangian cuts, derived from a Lagrangian relaxation of a specific reformulation of the subproblems in each stage, where local copies of state variables are introduced. We show that the Lagrangian cuts satisfy a tightness condition and provide a rigorous proof of the finite convergence of SDDiP with probability one. We show that, under fairly reasonable assumptions, an MSIP problem with general state variables can be approximated by one with binary state variables to desired precision with only a modest increase in problem size. Thus our proposed SDDiP approach is applicable to very general classes of MSIP problems. Extensive computational experiments on three classes of real-world problems, namely electric generation expansion, financial portfolio management, and network revenue management, show that the proposed methodology is very effective in solving large-scale multistage stochastic integer optimization problems.},
author = {Zou, Jikai and Ahmed, Shabbir and Sun, Xu Andy},
doi = {10.1007/s10107-018-1249-5},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Zou, Ahmed, Sun - 2019 - Stochastic dual dynamic integer programming.pdf:pdf},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {Binary state variables,Multistage stochastic integer programming,Nested decomposition,Stochastic dual dynamic programming},
number = {1-2},
pages = {461--502},
publisher = {Springer Berlin Heidelberg},
title = {{Stochastic dual dynamic integer programming}},
url = {https://doi.org/10.1007/s10107-018-1249-5},
volume = {175},
year = {2019}
}
@article{Makela2000,
abstract = {Recent progress toward the application of process-based models in forest management includes the development of evaluation and parameter estimation methods suitable for models with causal structure, and the accumulation of data that can be used in model evaluation. The current state of the art of process modeling is discussed in the context of forest ecosystem management. We argue that the carbon balance approach is readily applicable for projecting forest yield and productivity, and review several carbon balance models for estimating stand productivity and individual tree growth and competition. We propose that to develop operational models, it is necessary to accept that all models may have both empirical and causal components at the system level. We present examples of hybrid carbon balance models and consider issues that currently require incorporation of empirical information at the system level. We review model calibration and validation methods that take account of the hybrid character of models. The operational implementation of process-based models to practical forest management is discussed. Methods of decision-making in forest management are gradually moving toward a more general, analytical approach, and it seems likely that models that include some process-oriented components will soon be used in forestry enterprises. This development is likely to run parallel with the further development of ecophysiologically based models.},
author = {M{\"{a}}kel{\"{a}}, Annikki and Landsberg, Joe and Ek, Alan R. and Burk, Thomas E. and Ter-Mikaelian, Michael and {\AA}gren, G{\"{o}}ran I. and Oliver, Chadwick D. and Puttonen, Pasi},
doi = {10.1093/treephys/20.5-6.289},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/M{\"{a}}kel{\"{a}} et al/Tree Physiology/M{\"{a}}kel{\"{a}} et al. - 2000 - Process-based models for forest ecosystem management Current state of the art and challenges for practical implem.pdf:pdf},
issn = {0829318X},
journal = {Tree Physiology},
keywords = {Carbon allocation,Carbon balance,Competition,Stand productivity,Tree growth},
number = {5-6},
pages = {289--298},
pmid = {12651445},
title = {{Process-based models for forest ecosystem management: Current state of the art and challenges for practical implementation}},
volume = {20},
year = {2000}
}
@article{Mak1999,
abstract = {A stochastic program SP with solution value z* can be approximately solved by sampling n realizations of the program's stochastic parameters, and by solving the resulting `approximating problem' for (x*n, z*n). We show that, in expectation, z*n is a lower bound on z* and that this bound monotonically improves as n increases. The first result is used to construct confidence intervals on the optimality gap for any candidate solution x to SP, e.g., x = x*n. A sampling procedure based on common random numbers ensures nonnegative gap estimates and provides significant variance reduction over naive sampling on four test problems.},
author = {Mak, Wai Kei and Morton, David P. and Wood, R. Kevin},
doi = {10.1016/S0167-6377(98)00054-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Mak, Morton, Wood - 1999 - Monte Carlo bounding techniques for determining solution quality in stochastic programs.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {con{\"{y}}dence intervals,monte carlo approximations,programming,sampling,statistics,stochastic,variance},
number = {1},
pages = {47--56},
title = {{Monte Carlo bounding techniques for determining solution quality in stochastic programs}},
volume = {24},
year = {1999}
}
@article{Barnett2017,
abstract = {Progressive hedging, though an effective heuristic for solving stochastic mixed integer programs (SMIPs), is not guaranteed to converge in this case. Here, we describe BBPH, a branch and bound algorithm that uses PH at each node in the search tree such that, given sufficient time, it will always converge to a globally optimal solution. In addition to providing a theoretically convergent “wrapper” for PH applied to SMIPs, computational results demonstrate that for some difficult problem instances branch and bound can find improved solutions after exploring only a few nodes.},
author = {Barnett, Jason and Watson, Jean Paul and Woodruff, David L.},
doi = {10.1016/j.orl.2016.11.006},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Barnett, Watson, Woodruff - 2017 - BBPH Using progressive hedging within branch and bound to solve multi-stage stochastic mixed integer.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {Branch and bound,Progressive hedging,Stochastic programming},
number = {1},
pages = {34--39},
title = {{BBPH: Using progressive hedging within branch and bound to solve multi-stage stochastic mixed integer programs}},
volume = {45},
year = {2017}
}
@article{Emelogu2016,
abstract = {Choosing the appropriate sample size in Sample Average Approximation (SAA) method is very challenging. Inappropriate sample size can lead to the generation of low quality solutions with high computational burden. To overcome this challenge, our study proposes an enhanced SAA algorithm that utilizes clustering techniques to dynamically update the sample sizes and offers high quality solutions in a reasonable amount of time. We evaluate this proposed algorithm in the context of a facility location problem [FLP]. A number of numerical experiments (e.g., impact of different clustering techniques, fixed vs. dynamic clusters) are performed for various problem instances to illustrate the effectiveness of the proposed method. Results indicate that on average, enhanced SAA with fixed clustering size and dynamic clustering size solves [FLP] almost 631{\%} and 699{\%} faster than the basic SAA algorithm, respectively. Furthermore, it is observed that there is no single winner among the clustering techniques to solve all the problem instances of enhanced SAA algorithm and the performance is highly impacted by the size of the problems.},
author = {Emelogu, Adindu and Chowdhury, Sudipta and Marufuzzaman, Mohammad and Bian, Linkan and Eksioglu, Burak},
doi = {10.1016/j.ijpe.2016.08.032},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Emelogu et al. - 2016 - An enhanced sample average approximation method for stochastic optimization.pdf:pdf},
issn = {09255273},
journal = {International Journal of Production Economics},
keywords = {Facility location problem,Fuzzy C-means,K-means,K-means++,K-means||,Sample average approximation,Scenario clustering},
pages = {230--252},
publisher = {Elsevier},
title = {{An enhanced sample average approximation method for stochastic optimization}},
url = {http://dx.doi.org/10.1016/j.ijpe.2016.08.032},
volume = {182},
year = {2016}
}
@article{Beraldi2013,
abstract = {{\textcopyright} Sociedad de Estad{\'{i}}stica e Investigaci{\'{o}}n Operativa 2013.This paper deals with the problem of scenario tree reduction for stochastic programming problems. In particular, a reduction method based on cluster analysis is proposed and tested on a portfolio optimization problem. Extensive computational experiments were carried out to evaluate the performance of the proposed approach, both in terms of computational efficiency and efficacy. The analysis of the results shows that the clustering approach exhibits good performance also when compared with other reduction approaches.},
author = {Beraldi, Patrizia and Bruni, Maria Elena},
doi = {10.1007/s11750-013-0305-9},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Beraldi, Bruni - 2013 - A clustering approach for scenario tree reduction An application to a stochastic programming portfolio optimizat.pdf:pdf},
issn = {18638279},
journal = {Top},
keywords = {Clustering algorithms,Portfolio optimization,Scenario tree reduction,Stochastic programming},
number = {3},
pages = {1--16},
title = {{A clustering approach for scenario tree reduction: An application to a stochastic programming portfolio optimization problem}},
volume = {22},
year = {2013}
}
@article{Casey2005,
abstract = {A multistage stochastic linear program (MSLP) is a model of sequential$\backslash$nstochastic optimization where the objective and constraints are linear.$\backslash$nWhen any of the random variables used in the MSLP are continuous,$\backslash$nthe problem is infinite dimensional. To numerically tackle such a$\backslash$nproblem, we usually replace it with a finite-dimensional approximation.$\backslash$nEven when all the random variables have finite support, the problem$\backslash$nis often computationally intractable and must be approximated by$\backslash$na problem of smaller dimension. One of the primary challenges in$\backslash$nthe field of stochastic programming deals with discovering effective$\backslash$nways to evaluate the importance of scenarios and to use that information$\backslash$nto trim the scenario tree in such a way that the solution to the$\backslash$nsmaller optimization problem is not much different from the problem$\backslash$nstated with the original tree. The scenario generation (SG) algorithm$\backslash$nproposed in this paper is a finite-element method that addresses$\backslash$nthis problem for the class of MSLP with random right-hand sides.},
author = {Casey, Michael S. and Sen, Suvrajeet},
doi = {10.1287/moor.1050.0146},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Casey, Sen - 2005 - The Scenario Generation Algorithm for Multistage Stochastic Linear Programming.pdf:pdf},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
number = {3},
pages = {615--631},
title = {{The Scenario Generation Algorithm for Multistage Stochastic Linear Programming}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1050.0146},
volume = {30},
year = {2005}
}
@article{Latta2009,
abstract = {Regional estimation of potential forest productivity is important to diverse applications, including biofuels supply, carbon sequestration, and projections of forest growth. Using PRISM (Parameter-elevation Regressions on Independent Slopes Model) climate and productivity data measured on a grid of 3356 Forest Inventory and Analysis plots in Oregon and Washington, we evaluated four possible imputation methods to estimate potential forest productivity: nearest neighbour, multiple linear regression, thin plate spline functions, and a spatial autoregressive model. Productivity, measured by potential mean annual increment at culmination, is explained by the interaction of annual temperature, precipitation, and climate moisture index. The data were randomly divided into 2237 reference plots and 1119 target plots 30 times. Each imputation method was evaluated by calculating the coefficient of determination, bias, and root mean square error of both the target and reference data set and was also tested for evidence of spatial autocorrelation. Potential forest productivity maps of culmination potential mean annual increment were produced for all Oregon and Washington timberland.},
author = {Latta, Gregory and Temesgen, Hailemariam and Barrett, Tara M.},
doi = {10.1139/X09-046},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Latta, Temesgen, Barrett - 2009 - Mapping and imputing potential productivity of Pacific Northwest forests using climate variables.pdf:pdf},
issn = {00455067},
journal = {Canadian Journal of Forest Research},
number = {6},
pages = {1197--1207},
title = {{Mapping and imputing potential productivity of Pacific Northwest forests using climate variables}},
volume = {39},
year = {2009}
}
@article{Boland2016,
author = {Boland, Natashia and Dumitrescu, Irina and Froyland, Gary and Kalinowski, Thomas},
doi = {10.1007/s10107-015-0970-6},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Boland et al. - 2016 - Minimum cardinality non-anticipativity constraint sets for multistage stochastic programming.pdf:pdf},
isbn = {1010701509},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {Endogeneous uncertainty,Multistage stochastic programming,Stochastic programming},
month = {may},
number = {1},
pages = {69--93},
publisher = {Springer Berlin Heidelberg},
title = {{Minimum cardinality non-anticipativity constraint sets for multistage stochastic programming}},
url = {http://link.springer.com/10.1007/s10107-015-0970-6},
volume = {157},
year = {2016}
}
@article{Yossiri2015,
abstract = {The production routing problem (PRP) is a generalization of the inventory routing problem and concerns the production and distribution of a single product from a production plant to multiple customers using capacitated vehicles in a discrete-and finite-time horizon. In this study, we consider the stochastic PRP with demand uncertainty in two-stage and multistage decision processes. The decisions in the first stage include production setups and customer visit schedules, while the production and delivery quantities are determined in the subsequent stages. We introduce formulations for the two problems, which can be solved by a branch-and-cut algorithm. To handle a large number of scenarios, we propose a Benders decomposition approach, which is implemented in a single branch-and-bound tree and enhanced through lower-bound lifting inequalities, scenario group cuts, and Pareto-optimal cuts. For the multistage problem, we also use a warm start procedure that relies on the solution of the simpler two-stage problem. Finally, we exploit the reoptimization capabilities of Benders decomposition in a sample average approximation method for the two-stage problem and in a rollout algorithm for the multistage problem. Computational experiments show that instances of realistic size can be solved to optimality for the two-stage and multistage problems, and that Benders decomposition provides significant speedups compared to a classical branch-and-cut algorithm.},
author = {Yossiri, Adulyasak and Cordeau, Jean Fran{\c{c}}ois and Jans, Raf},
doi = {10.1287/opre.2015.1401},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Yossiri, Cordeau, Jans - 2015 - Benders decomposition for production routing under demand uncertainty.pdf:pdf},
issn = {15265463},
journal = {Operations Research},
number = {4},
pages = {851--867},
title = {{Benders decomposition for production routing under demand uncertainty}},
volume = {63},
year = {2015}
}
@article{KazemiZanjani2016,
abstract = {We propose a Hybrid Scenario Cluster Decomposition (HSCD) heuristic for solving a large-scale multi-stage stochastic mixed-integer programming (MS-MIP) model corresponding to a supply chain tactical planning problem. The HSCD algorithm decomposes the original scenario tree into smaller sub-trees that share a certain number of predecessor nodes. Then, the MS-MIP model is decomposed into smaller scenario-cluster multi-stage stochastic sub-models coordinated by Lagrangian terms in their objective functions, in order to compensate the lack of non-anticipativity corresponding to common ancestor nodes of sub-trees. The sub-gradient algorithm is then implemented in order to guide the scenario-cluster sub-models into an implementable solution. Moreover, a Variable Fixing Heuristic is embedded into the sub-gradient algorithm in order to accelerate its convergence rate. Along with the possibility of parallelization, the HSCD algorithm provides the possibility of embedding various heuristics for solving scenario-cluster sub-models. The algorithm is specialized to lumber supply chain tactical planning under demand and supply uncertainty. An ad-hoc heuristic, based on Lagrangian Relaxation, is proposed to solve each scenario-cluster sub-model. Our experimental results on a set of realistic-scale test cases reveal the efficiency of HSCD in terms of solution quality and computation time.},
author = {{Kazemi Zanjani}, Masoumeh and {Sanei Bajgiran}, Omid and Nourelfath, Mustapha},
doi = {10.1016/j.ejor.2016.01.048},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Kazemi Zanjani, Sanei Bajgiran, Nourelfath - 2016 - A hybrid scenario cluster decomposition algorithm for supply chain tactical planning.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Lagrangian Relaxation,Multi-stage stochastic programming,Scenario decomposition,Sub-gradient method,Variable Fixing Heuristic},
number = {2},
pages = {466--476},
publisher = {Elsevier B.V.},
title = {{A hybrid scenario cluster decomposition algorithm for supply chain tactical planning under uncertainty}},
url = {http://dx.doi.org/10.1016/j.ejor.2016.01.048},
volume = {252},
year = {2016}
}
@article{Dupacova2000,
abstract = {A major issue in any application of multistage stochastic programming is the representation of the underlying random data process. We discuss the case when enough data paths can be generated according to an accepted parametric or nonparametric stochastic model. No assumptions on convexity with respect to the random parameters are required. We emphasize the notion of representative scenarios (or a representative scenario tree) relative to the problem being modeled. 1. Multistage stochastic programs In the general T -stage stochastic program we think of a stochastic data process $\omega$ = {\{}$\omega$ 1 , . . . , $\omega$ T −1 {\}} or $\omega$ = {\{}$\omega$ 1 , . . . , $\omega$ T {\}} whose realizations are (multidimensional) data trajectories and of a vector decision process x = {\{}x 1 , . . . , x T {\}}, a measurable function of $\omega$. The sequence of decisions and observations is x 1 , $\omega$ 1 , x 2 (x 1 , $\omega$ 1), $\omega$ 2 , . . . , x T (x 1 , x 2 , . . . , x T −1 , $\omega$ 1 , . . . , $\omega$ T −1) = x T (x 1 , $\omega$ 1 , . . . , $\omega$ T −1). (1) In addition, $\omega$ T may contribute to the overall costs. The decision process is nonantic-ipative in the sense that decisions taken at any stage of the process do not depend on future realizations of the random parameters or on future decisions, whereas it is the past information and the given probabilistic specification ((, F, P) of the process $\omega$},
author = {Dupacov{\'{a}}, Jitka and Consigli, Giorgio and Wallace, Stein W},
doi = {10.1023/A:1019206915174},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Dupacov{\'{a}}, Consigli, Wallace - 2000 - Scenarios for Multistage Stochastic Programs.pdf:pdf;:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Dupacov{\'{a}}, Consigli, Wallace - 2000 - Scenarios for Multistage Stochastic Programs(2).pdf:pdf},
isbn = {0254-5330},
issn = {1572-9338},
journal = {Annals of Operations Research},
keywords = {clustering,importance sampling,inference and bounds,matching moments,problem oriented requirements,scenarios and scenario trees},
pages = {25--53},
title = {{Scenarios for Multistage Stochastic Programs}},
volume = {100},
year = {2000}
}
@article{Li2018a,
author = {Li, Q. Q. and Li, Y. P. and Huang, G H and Wang, C X},
doi = {10.1007/s00477-017-1490-0},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Li et al. - 2018 - Risk aversion based interval stochastic programming approach for agricultural water management under uncertainty.pdf:pdf},
isbn = {0047701714},
issn = {1436-3240},
journal = {Stochastic Environmental Research and Risk Assessment},
keywords = {agricultural irrigation {\'{a}} conditional,programming {\'{a}} water resources,risk {\'{a}} crop planning,value at,{\'{a}} multistage {\'{a}} stochastic},
month = {mar},
number = {3},
pages = {715--732},
title = {{Risk aversion based interval stochastic programming approach for agricultural water management under uncertainty}},
url = {http://link.springer.com/10.1007/s00477-017-1490-0},
volume = {32},
year = {2018}
}
@article{Alonso-Ayuso2018,
author = {Alonso-Ayuso, Antonio and Escudero, Laureano F. and Guignard, Monique and Weintraub, Andres},
doi = {10.1016/j.ejor.2017.12.022},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Alonso-Ayuso et al/European Journal of Operational Research/Alonso-Ayuso et al. - 2018 - Risk management for forestry planning under uncertainty in demand and prices.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
month = {jun},
number = {3},
pages = {1051--1074},
title = {{Risk management for forestry planning under uncertainty in demand and prices}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221717311414},
volume = {267},
year = {2018}
}
@article{Boland2017,
abstract = {We present a new primal-dual algorithm for computing the value of the Lagrangian dual of a stochastic mixed-integer program (SMIP) formed by relaxing its nonanticipativity constraints. This dual is widely used in decomposition methods for the solution of SMIPs. The algorithm relies on the well-known progressive hedging method, but unlike previous progressive hedging approaches for SMIP, our algorithm can be shown to converge to the optimal Lagrangian dual value. The key improvement in the new algorithm is an inner loop of optimized linearization steps, similar to those taken in the classical Frank-Wolfe method. Numerical results demonstrate that our new algorithm empirically outperforms the standard implementation of progressive hedging for obtaining bounds in SMIP.},
archivePrefix = {arXiv},
arxivId = {1702.00880},
author = {Boland, Natashia and Christiansen, Jeffrey and Dandurand, Brian and Eberhard, Andrew and Linderoth, Jeff and Luedtke, James and Oliveira, Fabricio},
doi = {10.1137/16M1076290},
eprint = {1702.00880},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Boland et al. - 2018 - Combining Progressive Hedging with a Frank--Wolfe Method to Compute Lagrangian Dual Bounds in Stochastic Mixed-In.pdf:pdf},
isbn = {0363-0129},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
month = {jan},
number = {2},
pages = {1312--1336},
title = {{Combining Progressive Hedging with a Frank--Wolfe Method to Compute Lagrangian Dual Bounds in Stochastic Mixed-Integer Programming}},
url = {https://epubs.siam.org/doi/10.1137/16M1076290},
volume = {28},
year = {2018}
}
@article{Bachmatiuk2016,
abstract = {Due to the long time horizon typically characterizing forest planning, uncertainty plays an important role when developing forest management plans. Especially important is the uncertainty related to recently human-induced global warming since it has a clear impact on forest capacity to contribute to biogenic and anthropogenic ecosystem services. If the forest manager ignores uncertainty, the resulting forest management plan may be sub-optimal, in the best case. This paper presents a methodology to incorporate uncertainty due to climate change into forest management planning. Specifically, this paper addresses the problem of harvest planning, i.e., defining which stands are to be cut in each planning period in order to maximize expected net revenues, considering several climate change scenarios. This study develops a solution approach for a planning problem for a eucalyptus forest with 1000 stands located in central Portugal where expected future conditions are anticipated by considering a set of climate scenarios. The model including all the constraints that link all the scenarios and spatial adjacency constraints leads to a very large problem that can only be solved by decomposing it into scenarios. For this purpose, we solve the problem using Progressive Hedging (PH) algorithm, which decomposes the problem into scenario sub-problems easier to solve. To analyze the performance of PH versus the use of the extensive form (EF), we solve several instances of the original problem using both approaches. Results show that PH outperforms the EF in both solving time and final optimality gap. In addition, the use of PH allows to solve the most difficult problems while the commercial solvers are not able to solve the EF. The approach presented allows the planner to develop more robust management plans that incorporate the uncertainty due to climate change in their plans.},
author = {Garcia-Gonzalo, Jordi and Pais, Crist{\'{o}}bal and Bachmatiuk, Joanna and Barreiro, Susana and Weintraub, Andres},
doi = {10.3390/f11020224},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Garcia-Gonzalo et al. - 2020 - A Progressive Hedging Approach to Solve Harvest Scheduling Problem under Climate Change.pdf:pdf},
issn = {1999-4907},
journal = {Forests},
keywords = {adjacency,harvest scheduling,progressive hedging,stochastic programming},
month = {feb},
number = {2},
pages = {224},
title = {{A Progressive Hedging Approach to Solve Harvest Scheduling Problem under Climate Change}},
url = {https://www.mdpi.com/1999-4907/11/2/224},
volume = {11},
year = {2020}
}
@article{MohammadiBidhandi2017,
abstract = {This paper proposes an accelerated solution method to solve two-stage stochastic programming problems with binary variables in the first stage and continuous variables in the second stage. To develop the solution method, an accelerated sample average approximation approach is combined with an accelerated Benders' decomposition algorithm. The accelerated sample average approximation approach improves the main structure of the original technique through the reduction in the number of mixed integer programming problems that need to be solved. Furthermore, the recently accelerated Benders' decomposition approach is utilized to expedite the solution time of the mixed integer programming problems. In order to examine the performance of the proposed solution method, the computational experiments are performed on developed stochastic supply chain network design problems. The computational results show that the accelerated solution method solves these problems efficiently. The synergy of the two accelerated approaches improves the computational procedure by an average factor of over 42{\%}, and over 12{\%} in comparison with the original and the recently modified methods, respectively. Moreover, the betterment of the computational process increases substantially with the size of the problem.},
author = {{Mohammadi Bidhandi}, Hadi and Patrick, Jonathan},
doi = {10.1016/j.apm.2016.09.019},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Mohammadi Bidhandi, Patrick - 2017 - Accelerated sample average approximation method for two-stage stochastic programming with binary fi.pdf:pdf},
issn = {0307904X},
journal = {Applied Mathematical Modelling},
keywords = {Benders' decomposition,Mixed integer linear programming,Sample average approximation,Supply chain network design,Two-stage stochastic programming},
pages = {582--595},
publisher = {Elsevier Inc.},
title = {{Accelerated sample average approximation method for two-stage stochastic programming with binary first-stage variables}},
url = {http://dx.doi.org/10.1016/j.apm.2016.09.019},
volume = {41},
year = {2017}
}
@article{Rios2016,
abstract = {{\textcopyright} 2016 Taylor {\&} Francis.We analyse how to deal with the uncertainty before solving a stochastic optimization problem and we apply it to a forestry management problem. In particular, we start from historical data to build a stochastic process for wood prices and for bounds on its demand. Then, we generate scenario trees considering different numbers of scenarios and different scenario-generation methods, and we describe a procedure to compare the solutions obtained with each approach. Finally, we show that the scenario tree used to obtain a candidate solution has a considerable impact in our decision model.},
author = {Rios, Ignacio and Weintraub, Andres and Wets, Roger J.B.},
doi = {10.1080/14697688.2015.1114365},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Rios, Weintraub, Wets - 2016 - Building a stochastic programming model from scratch a harvesting management example.pdf:pdf},
issn = {14697696},
journal = {Quantitative Finance},
keywords = {Scenario generation,Scenario trees,Stochastic evaluation,Stochastic programming},
number = {2},
pages = {189--199},
title = {{Building a stochastic programming model from scratch: a harvesting management example}},
volume = {16},
year = {2016}
}
@article{Watson2014,
author = {Watson, Jean-paul and Woodruff, David L},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Watson, Woodruff - 2014 - PYSP User Documentation.pdf:pdf},
pages = {1--34},
title = {{PYSP User Documentation}},
year = {2014}
}
@article{Makinen2013,
author = {M{\"{a}}kinen, A and Borges, J G},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/M{\"{a}}kinen, Borges - 2013 - Review . Assessing uncertainty and risk in forest planning and decision support systems review of classical me.pdf:pdf},
journal = {Forest Systems},
keywords = {endogenous risk,forest level,operations research,optimal alternative,s,stand level,stochastic risk},
number = {2},
pages = {282--303},
title = {{Review . Assessing uncertainty and risk in forest planning and decision support systems : review of classical methods}},
volume = {22},
year = {2013}
}
@article{Aldasoro2017,
abstract = {A parallel matheuristic algorithm is presented as a spin-off from the exact Branch-and-Fix Coordination (BFC) algorithm for solving multistage stochastic mixed 0–1 problems. Some steps to guarantee the solution's optimality are relaxed in the BFC algorithm, such that an incomplete backward branching scheme is considered for solving large sized problems. Additionally, a new branching criterion is considered, based on dynamically-guided and stage-wise ordering schemes, such that fewer Twin Node Families are expected to be visited during the execution of the so-called H-DBFC algorithm. The inner parallelization IH-DBFC of the new approach, allows to solve in parallel scenario clusters MIP submodels at different steps of the algorithm. The outer parallel version, OH-DBFC, considers independent paths and allows iterative incumbent solution values exchanges to obtain tighter bounds of the solution value of the original problem. A broad computational experience is reported for assessing the quality of the matheuristic solution for large sized instances. The instances dimensions that are considered are up to two orders of magnitude larger than in some other works that we are aware of. The optimality gap of the H-DBFC solution value versus the one obtained by a state-of-the-art MIP solver is very small, if any. The new approach frequently outperforms it in terms of solution's quality and computing time. A comparison with our Stochastic Dynamic Programming algorithm is also reported. The use of parallel computing provides, on one hand, a perspective for solving very large sized instances and, on the other hand, an expected large reduction in elapsed time.},
author = {Aldasoro, Unai and Escudero, Laureano F. and Merino, Mar{\'{i}}a and P{\'{e}}rez, Gloria},
doi = {10.1016/j.ejor.2016.08.072},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Aldasoro et al. - 2017 - A parallel Branch-and-Fix Coordination based matheuristic algorithm for solving large sized multistage stochast.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Branch-and-Fix Coordination,Break stage scenario clustering,Matheuristic,Message-passing interface,Multistage stochastic mixed 0–1 Optimization,Parallel computing},
month = {apr},
number = {2},
pages = {590--606},
title = {{A parallel Branch-and-Fix Coordination based matheuristic algorithm for solving large sized multistage stochastic mixed 0–1 problems}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221716307111},
volume = {258},
year = {2017}
}
@article{Chen2018,
author = {Chen, Zhiping and Yan, Zhe},
doi = {10.1002/asmb.2290},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Chen, Yan - 2018 - Practical arbitrage-free scenario tree reduction methods and their applications in financial optimization.pdf:pdf},
issn = {15241904},
journal = {Applied Stochastic Models in Business and Industry},
month = {mar},
number = {2},
pages = {175--195},
title = {{Practical arbitrage-free scenario tree reduction methods and their applications in financial optimization}},
url = {http://doi.wiley.com/10.1002/asmb.2290},
volume = {34},
year = {2018}
}
@article{Pflug2001,
abstract = {Multiperiod financial optimization is usually based on a stochastic model for the possible market situations. There is a rich literature about modeling and estimation of continuous-state financial processes, but little attention has been paid how to approximate such a process by a discrete-state scenario process and how to measure the pertaining approximation error. In this paper we show how a scenario tree may be constructed in an optimal manner on the basis of a simulation model of the underlying financial process by using a stochastic approximation technique. Consistency relations for the tree may also be taken into account},
author = {Pflug, Georg Ch},
doi = {10.1007/s101070000202},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Pflug - 2001 - Scenario tree generation for multiperiod financial optimization by optimal discretization.pdf:pdf},
journal = {Mathematical Programming, series B},
pages = {251--271},
title = {{Scenario tree generation for multiperiod financial optimization by optimal discretization}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2FPL00011398.pdf},
volume = {89},
year = {2001}
}
@article{Coniglio2017,
abstract = {{\textcopyright} 2017 The Author(s) We address a variant of the single item lot sizing problem affected by proportional storage (or inventory) losses and uncertainty in the product demand. The problem has applications in, among others, the energy sector, where storage losses (or storage deteriorations) are often unavoidable and, due to the need for planning ahead, the demands can be largely uncertain. We first propose a two-stage robust optimization approach with second-stage storage variables, showing how the arising robust problem can be solved as an instance of the deterministic one. We then consider a two-stage approach where not only the storage but also the production variables are determined in the second stage. After showing that, in the general case, solutions to this problem can suffer from acausality (or anticipativity), we introduce a flexible affine rule approach which, albeit restricting the solution set, allows for causal production plans. A hybrid robust-stochastic approach where the objective function is optimized in expectation, as opposed to in the worst-case, while retaining robust optimization guarantees of feasibility in the worst-case, is also discussed. We conclude with an application to heat production, in the context of which we compare the different approaches via computational experiments on real-world data.},
author = {Coniglio, Stefano and Koster, Arie M.C.A. and Spiekermann, Nils},
doi = {10.1007/s10878-017-0147-8},
file = {:C$\backslash$:/Users/Martins/Documents/Mendeley Desktop/Coniglio, Koster, Spiekermann - 2017 - Lot sizing with storage losses under demand uncertainty.pdf:pdf},
issn = {15732886},
journal = {Journal of Combinatorial Optimization},
keywords = {Affine rules,Lot sizing,Stochastic programming,Storage losses/deterioration,Two-stage robust optimization,Uncertain demand},
pages = {1--26},
publisher = {Springer US},
title = {{Lot sizing with storage losses under demand uncertainty}},
year = {2017}
}
@article{Ross2016, title={A model for managing edge effects in harvest scheduling using spatial optimization}, volume={31}, DOI={10.1080/02827581.2016.1213877}, number={7}, journal={Scandinavian Journal of Forest Research}, author={Ross, Kai L. and T\'oth, Sándor F.}, year={2016}, pages={646–654}}
@article{heltorp2017, title={Do forest decision-makers in Southeastern Norway adapt forest management to climate change?}, volume={33}, DOI={10.1080/02827581.2017.1362463}, number={3}, journal={Scandinavian Journal of Forest Research}, author={Heltorp, Kaja Mathilde Aamodt and Kangas, Annika and Hoen, Hans Fredrik}, year={2017}, pages={278–290}}
@article{bagaram_AD, title={Stochastic Harvest Scheduling under Climate Change}, journal={Operations research perspectives}, author={Bagaram, Martin B. and T\'oth, Sándor and Weintraub, Andres}, year={forthcoming}}
@article{Garcia-Gonzalo2020,
abstract = {Due to the long time horizon typically characterizing forest planning, uncertainty plays an important role when developing forest management plans. Especially important is the uncertainty related to recently human-induced global warming since it has a clear impact on forest capacity to contribute to biogenic and anthropogenic ecosystem services. If the forest manager ignores uncertainty, the resulting forest management plan may be sub-optimal, in the best case. This paper presents a methodology to incorporate uncertainty due to climate change into forest management planning. Specifically, this paper addresses the problem of harvest planning, i.e., defining which stands are to be cut in each planning period in order to maximize expected net revenues, considering several climate change scenarios. This study develops a solution approach for a planning problem for a eucalyptus forest with 1000 stands located in central Portugal where expected future conditions are anticipated by considering a set of climate scenarios. The model including all the constraints that link all the scenarios and spatial adjacency constraints leads to a very large problem that can only be solved by decomposing it into scenarios. For this purpose, we solve the problem using Progressive Hedging (PH) algorithm, which decomposes the problem into scenario sub-problems easier to solve. To analyze the performance of PH versus the use of the extensive form (EF), we solve several instances of the original problem using both approaches. Results show that PH outperforms the EF in both solving time and final optimality gap. In addition, the use of PH allows to solve the most difficult problems while the commercial solvers are not able to solve the EF. The approach presented allows the planner to develop more robust management plans that incorporate the uncertainty due to climate change in their plans.},
author = {Garcia-Gonzalo, Jordi and Pais, Crist{\'{o}}bal and Bachmatiuk, Joanna and Barreiro, Susana and Weintraub, Andres},
doi = {10.3390/f11020224},
issn = {1999-4907},
journal = {Forests},
keywords = {adjacency,harvest scheduling,progressive hedging,stochastic programming},
month = {feb},
number = {2},
pages = {224},
title = {{A Progressive Hedging Approach to Solve Harvest Scheduling Problem under Climate Change}},
url = {https://www.mdpi.com/1999-4907/11/2/224},
volume = {11},
year = {2020}
}
@article{Toth2009,
abstract = {Conservation efforts often require site or parcel selection strategies that lead to spatially cohesive reserves. Although habitat contiguity is thought to be conducive to the persistence of many sensitive species, availability of funding and suitable land may restrict the extent to which this spatial attribute can be pursued in land management or conservation. Using optimization modeling, we explore the economic and spatial tradeoffs of retaining or restoring grassland habitat in contiguous patches of various sizes near the Chicago metropolitan area. The underlying mathematical construct is the first exact, generalized formulation that directly models spatial contiguity in optimal reserve selection. The construct allows conservation planners to analyze and weigh different minimum contiguous habitat size requirements that are to be used in specific land acquisition or retention projects. {\textcopyright} 2009 Elsevier Ltd.},
author = {T{\'{o}}th, S{\'{a}}ndor F. and Haight, Robert G. and Snyder, Stephanie A. and George, Sonney and Miller, James R. and Gregory, Mark S. and Skibbe, Adam M.},
doi = {10.1016/j.biocon.2009.02.037},
file = {:C$\backslash$:/Users/martb/Downloads/1-s2.0-S0006320709001098-main.pdf:pdf},
issn = {00063207},
journal = {Biological Conservation},
keywords = {0-1 Programming,Contiguity,Reserve design,Spatial optimization,Urban sprawl},
number = {8},
pages = {1617--1627},
publisher = {Elsevier Ltd},
title = {{Reserve selection with minimum contiguous area restrictions: An application to open space protection planning in suburban Chicago}},
url = {http://dx.doi.org/10.1016/j.biocon.2009.02.037},
volume = {142},
year = {2009}
}
@article{StJohn2016a,
abstract = {Reindeer husbandry and commercial forestry seek to co-exist in the forests of Northern Sweden. As interwoven as the two industries are, conflicts have arisen. Forest practices have reduced the distribution of lichen, the main winter diet for reindeer. Forest practices have also increased forest density, compromising the animals' ability to pass through forested areas on their migration routes. In an attempt to reduce impacts on reindeer husbandry, we present a spatially explicit harvest scheduling model that includes reindeer corridors with user-defined spatial characteristics. We illustrate the model in a case study and explore the relationship between timber revenues and the selection and maintenance of reindeer corridors. The corridors are not only to include sufficient lichen habitat, but they are also supposed to ensure access for reindeer by connecting lichen areas with linkages that allow unobstructed travel. Since harvest scheduling occurs over a planning horizon, the spatial configuration of corridors can change from one time period to the next in order to accommodate harvesting activities. Our results suggest that maintaining reindeer corridors in harvest scheduling can be done at minimal cost. Also, we conclude that including corridor constraints in the harvest scheduling model is critical to guarantee connectivity of reindeer pastures.},
author = {{St John}, Rachel and {\"{O}}hman, Karin and T{\'{o}}th, S{\'{a}}ndor F. and Sandstr{\"{o}}m, Per and Korosuo, Anu and Eriksson, Ljusk Ola},
doi = {10.1080/02827581.2016.1195441},
file = {:C$\backslash$:/Users/martb/Downloads/Combining spatiotemporal corridor design for reindeer migration with harvest scheduling in Northern Sweden.pdf:pdf},
issn = {16511891},
journal = {Scandinavian Journal of Forest Research},
keywords = {Mixed-integer programming,forest management,reindeer husbandry,spatial optimization,wildlife conservation},
number = {7},
pages = {655--663},
publisher = {Taylor {\&} Francis},
title = {{Combining spatiotemporal corridor design for reindeer migration with harvest scheduling in Northern Sweden}},
volume = {31},
year = {2016}
}
@article{John2018,
abstract = {Wildlife corridors are often used to connect critical habitat for species protection. Mixed integer programming models have been used in the past to create wildlife corridors, but they lack the capacity to control corridor geometry. We propose an approach that employs path planning techniques from artificial intelligence to account for and control corridor geometry, such as width and length. By combining path planning with network optimization, our approach allows the user to control and optimize the geometric characteristics of wildlife corridors. We illustrate our approach on two realistic landscapes and present numerical results on several computer-generated landscapes. The computational results indicate that this approach is efficient and can address problems controlling corridor geometry that were previously thought intractable. The approach has potential applications in such areas as the selection of routes or barrier construction problems, an example of which is firebreak design.},
author = {St John, Rachel and T{\'{o}}th, S{\'{a}}ndor F. and Zabinsky, Zelda B.},
doi = {10.1287/opre.2018.1758},
file = {:C$\backslash$:/Users/martb/Downloads/opre.2018.1758.pdf:pdf},
issn = {15265463},
journal = {Operations Research},
keywords = {Artificial intelligence,Natural resources,Network optimization,Path planning},
number = {6},
pages = {1471--1485},
title = {{Optimizing the geometry of wildlife corridors in conservation reserve design}},
volume = {66},
year = {2018}
}
@article{Elli2020,
abstract = {Eucalyptus is the world's most planted hardwood tree. Concerns about potential impacts and uncertainties of climate change on Eucalyptus plantations productivity are arising and studies about that are still scarce. This study assesses the effects of climate change on Eucalyptus plantations productivity across a geographic gradient in Brazil by mid- and end-century and quantifies the uncertainty of climate and productivity projections. Ten global circulation models (GCM) under intermediate (RCP4.5) and high (RCP8.5) greenhouse gas emission scenarios, for the 2040–2069 and 2070–2099 periods were used for future climate projections. The APSIM Next Generation Eucalyptus model was used to simulate the Eucalyptus mean annual increment (MAI, m3 ha−1 yr−1) at seven years for eight locations in Brazil. The response of Eucalyptus productivity is expected to be site-specific and will mostly depend on the balance between the possible negative effects of increasing temperatures and the potential productivity increments caused by higher CO2 concentration. Plantations located in South and Southeast Brazil are expected to experience increases in MAI, while those located in Center-North Brazil will experience more pronounced MAI reductions. Uncertainties in projections are higher under RCP8.5 and for the end-of-century, especially for annual rainfall and MAI. Future climate projections from GCMs coupled with a Eucalyptus simulation model provide valuable information to facilitate the exploration of potential strategies and guidance of policy decision-making for forestry adaptation to climate change on a regional or national scale. However, forest companies and foresters should be cautious when using projected information for local-scale adaptation options, as the uncertainties in climate (especially in rainfall) and productivity projections are substantially large.},
author = {Elli, Elvis Felipe and Sentelhas, Paulo Cesar and Bender, Fabiani Denise},
doi = {10.1016/j.foreco.2020.118365},
file = {:C$\backslash$:/Users/martb/Downloads/1-s2.0-S0378112720311348-main.pdf:pdf},
issn = {03781127},
journal = {Forest Ecology and Management},
keywords = {APSIM Eucalyptus model,Climate change uncertainties,Eucalyptus productivity,Global circulation models,Temperature stresses},
number = {March},
pages = {118365},
publisher = {Elsevier},
title = {{Impacts and uncertainties of climate change projections on Eucalyptus plantations productivity across Brazil}},
url = {https://doi.org/10.1016/j.foreco.2020.118365},
volume = {474},
year = {2020}
}
@article{Schroder2016,
abstract = {Forest owners worldwide are increasingly interested in managing forests to provide a broad suite of ecosystem services, balancing multiple objectives and evaluating management activities in terms of potential tradeoffs. We describe a multi-objective mathematical programming model to quantify tradeoffs in expected sediment delivery and the preservation of Northern spotted owl (NSO) habitat following fuel treatments to reduce fire hazard in the Deschutes National forest in Central Oregon, USA. Our model integrates the management objective of fire hazard reduction and the provision of ecosystem services (water quality and NSO habitat protection) and helps evaluate tradeoffs among them. Our results suggest significant reductions in fire hazard can be achieved without compromising any NSO habitat by strategically placing the treatments; however, the treatments will lead to a short term increase in sediment delivery. An analysis of environmental risks showed that over the longer term, the increase in sediment delivery and NSO habitat loss caused by wildfires would be 30–50{\%} greater in areas without fuel treatments. The use of the multi-objective optimization model described in this study can help managers quantify and assess potential tradeoffs among ecosystem services and provide data for more informed decision making.},
author = {Schroder, Svetlana A.(Kushch) and T{\'{o}}th, S{\'{a}}ndor F. and Deal, Robert L. and Ettl, Gregory J.},
doi = {10.1016/j.ecoser.2016.08.006},
file = {:C$\backslash$:/Users/martb/Downloads/1-s2.0-S2212041616302157-main.pdf:pdf},
issn = {22120416},
journal = {Ecosystem Services},
keywords = {Ecosystem services,Environmental risk,Multi-objective optimization models,Northern spotted owl habitat,Tradeoffs,Water quality},
pages = {328--347},
publisher = {Elsevier},
title = {{Multi-objective optimization to evaluate tradeoffs among forest ecosystem services following fire hazard reduction in the Deschutes National Forest, USA}},
url = {http://dx.doi.org/10.1016/j.ecoser.2016.08.006},
volume = {22},
year = {2016}
}
@article{Moriguchia2020,
author = {Moriguchi, Kai and Ueki, Tatsuhito and Saito, Masashi},
doi = {10.1016/j.orp.2020.100158},
file = {:C$\backslash$:/Users/martb/Documents/Mendeley Desktop/1-s2.0-S2214716020300488-main.pdf:pdf},
issn = {2214-7160},
journal = {Operations Research Perspectives},
keywords = {Continuous approximation,Forest harvesting regulation,Net present value,Simulated annealing,continuous approximation,forest harvesting regulation},
number = {April},
pages = {100158},
publisher = {Elsevier},
title = {{Establishing optimal forest harvesting regulation with continuous approximation}},
url = {https://doi.org/10.1016/j.orp.2020.100158},
volume = {7},
year = {2020}
}
@article{Garcia-Gonzalo2016,
abstract = {An approach is proposed for incorporating the variations in timber growth and yield due to climate change uncertainty into the forest harvesting decision process. A range of possible climate scenarios are transformed by a forest growth and yield model into tree growth scenarios, which in turn are integrated into a multistage stochastic model that determines the timber cut in each future period so as to maximize net present value over the planning horizon. For comparison purposes, a deterministic model using a single average climate scenario is also developed. The performance of the deterministic and stochastic formulations are tested in a case study of a medium-term forest planning problem for a Eucalyptus forest in Portugal where climate change is expected to severely impact production in the coming years. Experiments conducted using 32 climate scenarios demonstrate the stochastic model's superior results in terms of present value, particularly in cases of relatively high minimum timber demand. The model should therefore be useful in supporting forest planners' decisions under climate uncertainty.},
author = {Garcia-Gonzalo, Jordi and Pais, Crist{\'{o}}bal and Bachmatiuk, Joanna and Weintraub, Andr{\'{e}}s},
doi = {10.1139/cjfr-2015-0468},
file = {:C$\backslash$:/Users/martb/Documents/Mendeley Desktop/garcia-gonzalo2016.pdf:pdf},
issn = {12086037},
journal = {Canadian Journal of Forest Research},
keywords = {Climate change,Forest planning,Forestry,Stochastic decision models,Uncertainty},
number = {9},
pages = {1111--1121},
title = {{Accounting for climate change in a forest planning stochastic optimization model}},
volume = {46},
year = {2016}
}